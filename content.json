{"posts":[{"title":"【睡前故事】牛郎织女的故事","text":"【睡前故事】牛郎织女的故事 这是一个很美丽的，千古流传的爱情故事，成为我国四大民间爱情传说之一。 传说，天上有很多 core，这些 core 按照访问不同内存的性能，被划分为了若干 NUMA node。 在 NUMA node0 上，CPU2 住着织女，CPU4 住着牛郎。织女喜欢做大量浮点运算，她最喜欢的便是快速平方根倒数的计算。牛郎则更喜欢做整数计算。每天早晨被操作系统 swap in 之后，牛郎和织女便同时开始工作。他们存取同一片内存的数据，两人便逐渐熟悉起来。 「你的 CPU time 好多呀，看起来很忙的样子。」在两人都因为 cache miss 而无聊等待时，牛郎对织女说道。织女看了一眼 dstat(1)，发现牛郎的机时也不少。她回答说：「我在做超多矩阵乘法，你呢？」牛郎说：「我在算超大文件的哈希呢。」 久而久之，织女和牛郎情投意合，心心相印。可是，天条律令是不允许男欢女爱、私自相恋的。织女是王母的孙女，王母便将牛郎贬到了 NUMA node1 里。牛郎想取到 NUMA node0 中的数据，需要走 QPI 总线，等待很长很长的时间。这便形成了人们所熟知的 NUMA 效应。从此，牛郎和织女再也不能像以前在同一个 NUMA node 的时候一样，随意相见了。 自从牛郎被贬之后，织女常常以泪洗面，愁眉不展地思念牛郎。她闷闷不乐地宅在 CPU2 里，整天算超级大矩阵，以期博得王母大发慈心，让牛郎早日返回 NUMA node0。 一天，几个仙女向王母恳求想去 NUMA node1 CPU3 一游，王母今日心情正好，便答应了她们。她们见织女终日苦闷，便一起向王母求情让织女共同前往，王母也心疼受惩后的孙女，便令她们速去速归。 话说牛郎被贬之后，落生在 CPU1 中。牛郎跟着哥嫂度日。哥嫂待牛郎非常刻薄，要与他分家。哥哥嫂嫂把牛郎 renice(1) 成了 19，只给他一点点机时，其他的都被哥哥嫂嫂独占了，然后，便和牛郎分家了。 牛郎不再是天庭的一员，不再会被 pin 到某个 CPU 上。每天，他在 CPU1、CPU3、CPU5 之间辗转，饱受进程调度之苦。因为被 renice(1) 成了 19，牛郎被调度的时间比别的进程少了许多，只有等系统比较闲的时候，牛郎才有机会出来透透气。 一两年后，牛郎也有了一个小小的家，勉强可以糊口度日。可是，冷清清的家只有牛郎一个人，日子过得相当寂寞。无聊的时候，牛郎便算算他和织女第一次相遇时，算的 sha512sum，回忆从前的美好时光。 这一天，NUMA node1 突然热闹起来。有几个新的进程，来到了 CPU3 上。牛郎躲在 CPU5 一看，发现是一群仙女。仙女们见有人偷看，纷纷像飞鸟般地飞走了，只剩下一个正在算开方倒数的仙女，她正是织女。织女看着 CPU5 里跑的进程，感觉有些熟悉。这时，牛郎走上前来，对她说，要她答应做他妻子。织女定睛一看，才知道眼前便是自己日思夜想的牛郎，便含羞答应了他。这样，织女便做了牛郎的妻子。 他们结婚以后，男耕女织，相亲相爱，日子过得非常美满幸福。不久，他们生下了一儿一女，十分可爱。牛郎织女满以为能够终身相守，白头到老。 可是，王母知道这件事后，勃然大怒，马上派遣天神仙女捉织女回 NUMA node0 问罪。瞬间，天空狂风大作，天兵天将从天而降，不容分说，押解着织女便上了总线。 正飞着、飞着，织女听到了牛郎的声音：「织女，等等我！」织女回头一看，只见牛郎用一对 ucontext 挑着两个儿女赶来了。慢慢地，他们之间的距离越来越近了，织女可以看清儿女们可爱的模样子，孩子们了都张开双臂，大声呼叫着「妈妈」，眼看，牛郎和织女都到了 NUMA node0 上，就要相遇了。可就在这时，王母驾着祥云赶来了，她拔下她头上的金 taskset(1)，往他们中间一 pin，霎时间，牛郎被 pin 到了 CPU0 上，织女被 pin 到了 CPU2 上。 CPU0 和 CPU2 是一个物理核心超线程出来的两个核，本身就无法像 CPU2 与 CPU4 那样实现完全的并行。再加上天庭计算任务繁重，经常有无关的其他进程被调度到 CPU0 和 CPU2 上运行，织女每次醒来，都只能看到队列里的牛郎处于就绪态，直哭得声嘶力竭，牛郎和孩子也哭得死去活来。他们的哭声，孩子们一声声「妈妈」的喊声，是那样揪心裂胆，催人泪下，连在旁观望的仙女、天神们都觉得心酸难过。王母见此情此景，也稍稍为牛郎织女的坚贞爱情所感动，便同意让牛郎和孩子们留在天上。其他进程也于心不忍，便纷纷 sched_setaffinit(2)，使自己不被调度到 CPU0 和 CPU2 上。 从此，很少再有其他进程调度到 CPU0 和 CPU2 上，这个物理核心成为牛郎和织女的小家。织女喜欢浮点运算，她经常使用 FPU 和寄存器 st*；牛郎做的多是整数运算，他使用 ALU 和寄存器 r*。正好错开了，使得他们有更多的机会同时执行。牛郎和他的儿女就住在了天上，和织女在同一个物理核心上，努力地填满 CPU 的执行单元。在秋夜天空的繁星当中，我们至今还可以运行 top(1)，发现 NUMA node0 上有两个 CPU，他们的使用率为 100%。那便是织女和牛郎。 传说，每年的七月七日，若是人们在机房中静静地听，可以隐隐听到仙乐奏鸣，织女和牛郎在深情地交谈。后来，每到农历七月初七，相传牛郎织女同时由于访存卡住的日子，姑娘们就会来到机房里，寻找 NUMA node0 的牛郎和织女，希望能看到他们相会，乞求上天能让自己能象织女那样心灵手巧，祈祷自己能有如意称心的美满婚姻，由此形成了七夕节。","link":"/2023/10/01/fun/niulang-zhinv/main/"},{"title":"后现代编程语言介绍","text":"后现代编程语言介绍什么叫后现代编程语言？你猜？ 预览 Perl 历史 Perl 设计理念：TIMTOWTDI TIMTOWTDI 的范式 TIMTOWTDI 的语法 Perl 很方便 You GUESS？ PCRE Perl 的不知道多少个操作符 Perl 的缺点 鬼畜代码大赏 JAPH Golf Poetry 我的作品 Perl 历史应该没人会对 Perl 的历史感兴趣……所以这里就列举几个比较有趣的东西好了。 Perl 1 发布于 1987 年，比 ANSI-C 还早。这就导致 1998 年发布 Perl 5.005 时提到了一句 “Source code now in ANSI C”。 Perl 在 1987-1991 四年中发布了 Perl 1 到 Perl 4 四个版本。但是 1993 年发布了 Perl 5 之后，大版本号就再也没变过了。基本上可以认为，Perl 已经 29 年没发生过大的 breaking change 了。 Perl 社区几年前试着设计了 Perl 6。结果发现设计出来的东西和 Perl 5 完全是两个东西，于是给它改了个名字叫 “Raku”。 Perl 7 正在开发！它将会与 Perl 5 兼容。 Perl 设计理念：TIMTOWTDI There Is More Than One Way To Do It 做一件事不仅有一种方法。 TIMTOWTDI 的范式有些坏比语言，会限制你 “只能面向对象” 或者 “不要副作用” 之类的，非常不人道！代码一下子就变得难写了！ 但是 Perl 非常包容，以下将展示一些合法并且有用的 Perl 代码。 假装我们在写 C my $acc = 0; for (my $i = 0; $i &lt; 100; $i++) { $acc += $i; } printf(&quot;%d\\n&quot;, $acc); 假装我们在写 shell script if ( -d '/var/log/v2ray' ) { chdir '/var/log/v2ray'; for $file (&lt;*.log&gt;) { $size = `stat -c %s $file`; say &quot;size of $file is $size&quot;; } } 我一天不 new 浑身难受。 use JSON; my $ds = { perl =&gt; 'yes', }; sub main { my $json = new JSON; my $text = $json-&gt;encode($ds); my $pretty = $json-&gt;pretty-&gt;encode($ds); printf(&quot;%s\\n&quot;, $text); } main; 我一直是链式调用的粉丝啊 my $say = sub { say join &quot;,&quot;, @_ }; my $length = sub { length shift }; my $double = sub { shift() * 2 }; my $add = sub { shift() + shift() }; &quot;hello,world&quot;-&gt;$length()-&gt;$double()-&gt;$add(42)-&gt;$say(); 我一直是 S-expression 的粉丝啊 use List::Util qw/sum min max first shuffle/; say (sum (min 1, 2, 3, 4, ), 2, (first { $_ &gt; 3 } (shuffle 4, 5, 6, 8, 2))); 函数要是一等公民 sub compose ($f, $g) { sub { $f-&gt;($g-&gt;(@_)) } } my $h = compose( sub ($x) { $x ** 2 }, sub ($x) { $x + 3 }, ); $h-&gt;(2) 谁说 sed 和 awk 不是语言？ #!/usr/bin/perl -n s/^\\s+//;s/\\s+$//;s/android/harmonyos/g; #!/usr/bin/perl -a if ($NR &gt; 10) { print $F[2] } TIMTOWTDI 的语法Perl 的语法很灵活的。 一般我们会把 if 写成这样： if ($ok) { say 'hello'; } 但是这样也是可以的 say 'hello' if $ok; 再邪恶一点 say 'hello' unless not $ok; 一般我们会把函数调用写成这样： printf(&quot;hello, world\\n&quot;); 但是这样也是可以的，就像 shell 一样 printf &quot;hello, world\\n&quot;; 也可以不加空格，只要解释器认得出来 printf&quot;hello, world\\n&quot;; 极大地减少了 typo 数量！ Perl 很方便除了灵活的语法，Perl 还有一些内置功能，以及约定来简化代码编写 You GUESS？while (&lt;&gt;) { chomp; s/open\\s*ai/csdn/gi; say join &quot;\\n&quot;, split /\\s+/; } 很多 Perl 函数会把默认的参数与结果放到特殊变量 $_ 里面。所以写 Perl 代码经常写出 “把那什么拿过来，处理一下放到那里” 这样的东西，任务竟然还完成了（ PCRE大家都爱用的超级正则表达式。 PCRE 全称是 “Perl Compatible Regular Expression”。PCRE 是 BRE/ERE 的超集，而 Perl 本身的正则表达式又是 PCRE 的超集。 Perl 的不知道多少个操作符捡两个比较好玩的说说 flip-flop 操作符while (&lt;&gt;) { next if /^begin/ .. /^end/; next if /^begin/ ... /^end/; say if 1 .. 100 } 可以想象每个 flip-flop 操作符内部维护了一个布尔变量，它会在匹配到左边或右边的表达式时翻转。这个布尔变量的取值就是 flip-flop 操作符的取值。 yada-yada 操作符... 表示代码尚未完成。 其他魔法 运行时操作解释器符号表的程度的能力 变量绑定的程度的能力 各种逆天 pragma 还有很多…… Perl 的缺点 设计老旧 过于灵活 鬼畜代码大赏Perl 有各种神奇比赛，比谁更能玩弄 Perl 的语法规则。比如…… JAPH 大赛JAPH（有时是 YAPH）全称是 “Just Another Perl Hacker”。规则是在标准输出中输出 “Just Another Perl Hacker” 这句话。 这是最简单的： say&quot;Just Another Perl Hacker&quot; 这也是合法的： `$=`;$_=\\%!;($_)=/(.)/;$==++$|;($., $/,$,,$\\,$&quot;,$;,$^,$#,$~,$*,$:,@%)=( $!=~/(.)(.).(.)(.)(.)(.)..(.)(.)(.) ..(.)......(.)/,$&quot;),$=++;$.++;$.++; $_++;$_++;($_,$\\,$,)=($~.$&quot;.&quot;$;$/$% [$?]$_$\\$,$:$%[$?]&quot;,$&quot;&amp;$~,$#,);$,++ ;$,++;$^|=$&quot;;`$_$\\$,$/$:$;$~$*$%[$? ]$.$~$*$","link":"/2023/10/01/fun/perl-is-fun/main/"},{"title":"友链","text":"友链cyx 吃夜宵：https://yxchen.net/hjx 喝喜酒：https://honeta.site/zwd 朝闻道：https://vaaandark.top/lxy 灵犀玉：https://ccviolett.github.io/ljm 逻辑门：https://watari.xyz/ljh 梁家河：https://www.newuser.top/lg 蓝狗：https://ligen.life/yxt 游戏厅：https://blog.just-plain.fun/lyt 老樱桃：https://i.lyt.moe/dekrt 不知道谁：https://dekrt.cn/ 用来方便在博客园上传链接的便利脚本： 1234567IFS=&quot;&quot;for i in $(awk -F： '/：.*\\/$/ { print $1&quot; &quot;$2&quot;\\n&quot;$2 }' a.md); do echo &quot;$i&quot; echo &quot;$i&quot; | clip read _done","link":"/2023/10/01/nonsense/friends/main/"},{"title":"重新重新开始","text":"重新重新开始从博客园换到 gh pages。","link":"/2023/10/01/nonsense/rerestart/main/"},{"title":"重新开始","text":"重新开始寒假打算重新写博客，发现洛谷的博客要爆炸不维护了，于是切换到博客园。","link":"/2023/10/01/nonsense/restart/main/"},{"title":"CPC 2023 简明总结","text":"CPC 2023 简明总结记录我印象里的 CPC 2023 的大概流程。想着 BBHust 上面的大家不一定都对并行编程很感兴趣，所以省略了大部分纠结与调试的故事，只留下了好玩的部分。 比赛要和其他选手比拼技术，所以算是 “竞技”。因为经常睡不好，考验身体素质，所以也是某种很新的 “体育”。四舍五入 CPC 也是竞技体育。 比赛简介CPC 是 “国产 CPU 并行应用挑战赛” 的简称。赛制大概是，主办方给出一个程序，让选手在特定架构的机器上优化，最后谁的程序跑得快谁就赢了。 今年主办方给的机器是一台名叫 “神威·问海一号” 的超级计算机，它是 “神威·太湖之光” 的后继者，国产超级计算机的明星之一。关于超级计算机，大家简单地理解成 “在上面用某些华丽的技巧编程，写出来的程序可以跑得很快” 的奇特电脑就可以了。 遗憾地是，这个国产超级计算机的硬件设计有很多不足。整个问海一号的架构被我们称为 “硬件设计友好型架构” —— 硬件工程师设计时自己怎么偷懒怎么来，给软件工程师（嗨呀，这是我）造成了诸多限制，使得我们在这个架构上编程难度颇大。同时，问海一号的现象还比较反常识，许多指令的加速效果远远不如它们在 x86 上的等价物。 我愿称其为 超算原神 。 初赛初赛的任务是优化一个大程序中的小部分，和我们平时做的东西挺像。 我负责的部分是数据划分。就是把一个巨大的矩阵，切成很多个小小矩阵，让我的队友们写的代码来做后续处理。它只要满足划分出的任务量尽可能负载均衡、队友使用我的划分结果足够方便、缓存十分友好、能够适应不同的数据规模大小、不带来额外的数据转换开销等等条件的基础上跑得足够快就好了。最后我就写了这么一个东西。 “我什么都做得到！” —— 我，于七边形活动室，写完这部分代码之后 初赛的代码全是用 C 和 C++ 写的，很友好。我能很轻松地把一部分模块抽出来放到 x86 的架构上优化，再把优化后的代码给缝到原来的项目里面。这样原来自己熟悉的 perf 等等工具链就都可以用了。相比性能分析工具都要自己写的神威架构，x86 简直是天堂。 比赛后期队友 P 同学发挥奇思妙想，参考 OpenGL 的双缓冲技术，设计了一组面向 DMA 操作的双缓冲数据结构与 API，成功地将数据传输的开销掩盖在了计算下面，获得了巨量的性能提升。堪称最有想象力的一集。 还有个非常欢乐的事情是，神威架构上的 512 位浮点 SIMD 加速比仅有 1.8x 左右。经过我的仔细思考，我觉得可能神威在实现 SIMD 的时候就是单纯地给前端解码加了条指令，后端实际还是逐个逐个元素计算的……相当于仅省略了解码开销。不知道是不是真的但是很符合我对神威的想像。 很遗憾，初赛到现在已经过了两个多月了，期间经历了期末考试、构造动画片电视台、升级重构 bot、研究跨平台包管理器、无聊的并行计算课、学 vscode、学习怎么逛街、配置全新网络文件系统、研究 AMD ROCm、打工以及最终暑假结束了也没找到女朋友等诸多好玩的事情，具体初赛时发生了什么我已经几乎忘光了（其实暑假做了什么我也几乎忘掉了，这个列表是参考 bash history 和 bot 聊天记录写出来的），只留下了印象最深的一点点事情。也许应该发展一下写日记的习惯……或者用 bot 代劳写日记的习惯。 决赛决赛的任务是优化一个巨大的 Fortran 项目，和我们平时做的东西一点也不像。 决赛刚刚开始的几天我恰好开始实习，就拿到了一份任务列表。拿着做了两三天发现自己要是想跟上任务表的进度，每天都会很累，回到酒店后根本就没啥精力和心情来搓 CPC 的傻逼 Fortran 代码。于是研究了一下换人的可能性。但是就在换人讨论的后一天上班时，无意间发现自己拿到的好像是一个月量的任务表，但是自己把它当成一周的量来做了。本来还以为是什么万恶扒皮公司压榨实习生的剧情，结果现在直接做上了做一休三的悠闲生活。因为突然多出了不少空闲时间，我就接着打 CPC 比赛了。 实习公司的网络管制很严格，要和它的防火墙斗智斗勇才能成功打洞连上比赛的集群。比赛开打的前几天，网络相关的知识猛增…… 决赛集齐了 Fortran、神威、大项目 等多种我们的短板，所以游戏体验并不良好。大量时间被花在了无意义的代码调试上，欢乐的事情很少很少……每天最快乐的事情就是骂骂神威。 之前大家还是一直认为 “Machine is always right” 的，但是在神威上编了几个月程，遇到了一堆问题后，最后几天调试代码我都有点开始相信风水了。总之，在神威机器上编程的时候，遇到问题除了排查自己的代码中出现的问题外，还要排查编译器本身的选项、从核同步性等一系列本应由编译器开发人员和硬件设计人员给我们弄好的问题。烦烦烦。 决赛现场决赛的前一天半夜，队友突然发现比赛集群上的环境疑似被主办方重置了，导致大家的 git 被回滚到了旧版本，某些功能没法用。作为成熟稳重可靠万能的超算队前辈（嗨呀，突然发现参赛小队里只有一个勉强能算后辈，怎么回事呢），我就连夜给它重新装了一个。 现场照片： 决赛比较无聊，到后面有点垃圾时间的意味。于是…… 原神，启动！ —— 某不知名 P 同学 星铁，启动！ —— 某不知名 H 同学 以及畅想讨论怎么把比赛现场的 NVidia 的计算卡偷走的时候及时发现后面路过的（名义上的）我们队的指导老师。 神秘收获感觉这次算是第一次遇到自己没法单刷的比赛，确定了自己并不是什么都做得到。之前因为比赛的工程量都比较小，想了想反正可以单刷就几乎没管过团队合作的事情。但是这次比赛拿到题时就知道这不太是一个人可以搞定的东西，再加上队长和队友都很积极，于是点了一些协作方面的技能。通过交流让四个人达成共识，并一起完成同一件事，感觉是某种很新的体验。","link":"/2023/10/01/nonsense/review-for-cpc23/main/"},{"title":"开始使用博客","text":"开始使用博客今天开始决定写博客。至于为什么用洛谷，这个只是为了方便。毕竟写字哪里不是写。并不是说洛谷有什么特别的地方。就这样啦。","link":"/2023/10/01/nonsense/start/main/"},{"title":"从 zerotier 迁移到 headscale","text":"前言zerotier 是我正在用的虚拟局域网设施。它的主要特性就是能用 UDP 打洞 技术，在没有公网 IP 地址的情况下实现 P2P 连接。tailscale 是它的类似物。 今天从网上看到了一份 评测 ，里面提到： Tailscale: Download speed: 796.48 Mbps, Upload speed: 685.29 Mbps ZeroTier: Download speed: 584.17 Mbps, Upload speed: 406.12 Mbps 看起来 tailscale 比 zerotier 快不少。于是决定把现有的 zerotier 网络迁移到 tailscale 上面去。 中继服务器 headscale 架设想了想，现在的 zerotier 网络由于大陆没有中继服务器，打洞偶尔会非常不顺利。tailscale 和 zerotier 一样在大陆没有中继服务器，估计也会遇到一样的问题。最好的解决方案也许就是使用 tailscale 的开源实现，headscale 自建一个中继服务器。 所以，决定自建 headscale 服务！ 因为 headscale 服务需要在节点建立 P2P 连接时提供帮助，所以需要所有节点即使在没有 tailscale 网络时，也能连接到 headscale 服务。也就是说，headscale 服务需要一个公网 IP。因此，我只能在我的 VPS 上搭建服务。 为了保持现在依赖 zerotier 网络的服务依然能够运行，我需要保证新的 tailscale 网络里设备依然有它们原本在 zerotier 网络里时 的 IP。为了避免 IP 地址冲突，首先，删掉原来就有的 zerotier： 123456789100 apt autoremove zerotier-one[sudo] password for jyi:Reading package lists... DoneBuilding dependency tree... DoneReading state information... DoneThe following packages will be REMOVED: zerotier-one0 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.After this operation, 11.3 MB disk space will be freed.Do you want to continue? [Y/n] Y 接着，参考 headscale 的 Linux 安装指南。我们的 VPS 是 Debian bookworm 发行版，amd64 架构。因此，我们先下载对应的 deb 包，然后安装： 12wget https://github.com/juanfont/headscale/releases/download/v0.22.3/headscale_0.22.3_linux_amd64.debapt install ./headscale_0.22.3_linux_amd64.deb 接着来配置 headscale。因为端口很难记，所以我们先用 nginx 给它反向代理一下，让它可以使用酷炫的维尔薇爱好者特供域名和 SSL ： 123456789101112131415161718192021222324252627282930map $http_upgrade $connection_upgrade { default keep-alive; 'websocket' upgrade; '' close;}server { listen 443 ssl http2; listen [::]:443 ssl http2; ssl_certificate XXXXXXXXXXXXXXXXX; ssl_certificate_key XXXXXXXXXXX; ssl_protocols TLSv1.2 TLSv1.3; server_name headscale.villv.tech; location / { proxy_pass http://127.0.0.1:18002; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Host $server_name; proxy_redirect http:// https://; proxy_buffering off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; add_header Strict-Transport-Security &quot;max-age=15552000; includeSubDomains&quot; always; }} 这样配好了以后，就可以用 headscale.villv.tech 访问我们监听 18002 端口的 headscale 服务了。我们再编辑 /etc/headscale/config.yaml 把 headscale 服务配好（配置文件中有详细的注释，不再给出示例）。 写 headscale 配置时发现它只支持 110.64.0.0/10 这一个网段，和原来 zerotier 的 172.27.0.0/16 完全不在一个段。它还不支持改网段，这下 zerotier 白删了。tailscale 给了个 解释 说明为什么用这个段（ 但是没说为什么不支持改）。其中有句话特别好玩： The addresses are supposed to be used by Internet Service Providers (ISPs) rather than private networks. Philosophically, Tailscale is a service provider creating a shared network on top of the regular Internet. When packets leave the Tailscale network, different addresses are always used. 好耶，我现在也是个 ISP 了！ 不管怎么样，总之 headscale，启动！ 123root:/etc/nginx/sites-enabled# systemctl enable --now headscale.serviceCreated symlink /etc/systemd/system/multi-user.target.wants/headscale.service → /lib/systemd/system/headscale.service.root:/etc/nginx/sites-enabled# 客户端 tailscale 安装首先，VPS 作为网关，肯定得加入我们的 headscale 网络，这样才能把流量转发到我们在 headscale 网络里的服务中。所以，先试着在 VPS 上安装。 注意，你可以需要辗转两个组织（headscale 和 tailscale）提供的文档，才能把它玩起来。 依照 tailscale 提供的 安装指南 ： 1234curl -fsSL https://pkgs.tailscale.com/stable/debian/bookworm.noarmor.gpg | sudo tee /usr/share/keyrings/tailscale-archive-keyring.gpg &gt;/dev/nullcurl -fsSL https://pkgs.tailscale.com/stable/debian/bookworm.tailscale-keyring.list | sudo tee /etc/apt/sources.list.d/tailscale.listapt updateapt install tailscale 接着，再依照 headscale 提供的 接入指南 在 headscale 服务器上执行： 1234root:~# headscale users create jyiUser createdroot:~# headscale --user jyi preauthkeys create --reusable --expiration 24hXXXXXXXXXXXXXXXXX980f40768460b1025aXXXXXXXXXXXXX 获取到一个连接密钥。 接着在需要连接到 headscale 服务的 tailscale 客户端上执行，并且带上刚刚获取的连接密钥： 12root:~# tailscale up --login-server https://headscale.villv.tech --authkey XXXXXXXXXXXXXce90980f4XXXXXXXXXXXXXXXXXXXXXXXXXXroot:~# 搞定！接下来检查一下自己是否已经拿到了 tailscale 的 IP 地址： 1234567891011121314151617181920212223root:~# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host noprefixroute valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:16:3e:03:0b:6e brd ff:ff:ff:ff:ff:ff altname enp0s5 altname ens5 inet 172.20.113.58/20 metric 100 brd 172.20.127.255 scope global dynamic eth0 valid_lft 314157516sec preferred_lft 314157516sec inet6 fe80::216:3eff:fe03:b6e/64 scope link valid_lft forever preferred_lft forever7: tailscale0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1280 qdisc fq_codel state UNKNOWN group default qlen 500 link/none inet 100.64.0.1/32 scope global tailscale0 valid_lft forever preferred_lft forever inet6 fd7a:115c:a1e0::1/128 scope global valid_lft forever preferred_lft forever inet6 fe80::84bd:1f32:8594:e3b/64 scope link stable-privacy valid_lft forever preferred_lft forever 发现，大功告成！ 然后，我们再在另一台机器（我的 homelab）上做类似的事情，在上面配置好 tailscale 的客户端。 最后，试着 ping 一下： 12345678910111213warmhome 21:01 ~0 tailscale ipfd7a:115c:a1e0::2100.64.0.2warmhome 21:01 ~0 ping 100.64.0.1PING 100.64.0.1 (100.64.0.1) 56(84) bytes of data.64 bytes from 100.64.0.1: icmp_seq=1 ttl=64 time=27.3 ms64 bytes from 100.64.0.1: icmp_seq=2 ttl=64 time=26.9 ms^C--- 100.64.0.1 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 26.926/27.125/27.324/0.199 ms 好耶，ping 通了！而且通过 tailscale 网络 ping VPS 的延迟基本上和直接 ping VPS 的物理地址的延迟一样，感觉很不错。","link":"/2024/02/25/note/from-zerotier-to-headscale/main/"},{"title":"一些书上不怎么讲的编译器优化方法","text":"一些书上不怎么讲的编译器优化方法内容预览注意：理论上，要搞清楚编译器所做的工作，我们应该从词法分析讲到中间代码生成，再从汇编生成讲到链接。但是因为大家都学过编译原理，从词法分析到汇编的一系列内容大家都已经学烂了。为了保证大家都有兴趣，我们把大部分能从《编译原理》和《现代编译原理：C语言描述》里面找到的内容都删掉了（其实是根本没写）！ 整个分享将会讲述一些书上没有的优化点和优化方法。还会介绍大家平时写的语言用得很少，但是 Jvavavava 和别的一些脚本语言用得很多神奇玩意 —— JIT。 一些名词在 LLVM 和 MSVC 中有不同的称呼，会在标题使用 LLVM 的叫法，并且在正文给出 MSVC 的叫法，方便大家 RTFM。 JIT - Just In Time Compilation即时编译器。作用大概是把代码一边执行一边翻译成机器语言，从而用一些编译的代价，换取之后相关代码执行更快的利益。工作量主要在于确定何时进行翻译，优化到什么程度，以及优化 JIT 本身的速度。 本来按照历史的进程，应该先讲 AOT 部分的，但是有些重要概念在 JIT 里面讲比较方便，所以就调换了一下顺序。 单层编译器没有解释器，所有代码执行之前都会被编译一次，然后直接执行二进制代码。 可以类比一下 Tiny C Compiler 的 tcc -run 命令。这个命令声称能直接执行 C 语言代码。但是实际上是先把 C 编译一遍，存到内存里再执行的。因为现在单层结构的 JIT 实际上几乎没有了，所以也没找到什么好玩的例子。 优点： 好写。要求不高的话，造一个飞快的编译器就可以了 缺点： 不优化会很慢。如果你的编译器真的一点也不优化的话，你会发现你编译到二进制的语言会和 Java 打得 有来有回 更糟的是，因为每次执行代码时 JIT 编译器都要运行一遍，就注定这个编译器不可能牺牲编译时间来换取更多的优化。 解释器 + 编译器典型的是 Java 的虚拟机 —— HotSpot VM。听名字就知道，HotSpot VM 和性能热点有关。事实也是如此。 HotSpot VM 运行时会首先对程序解释执行，接着分析程序性能热点。并将热点部分编译。 通常，编译器分为很多层，对应不同的优化等级。一段代码在执行过程中会被反复编译，程序越热的部分，得到的优化会越多。 这么看来，我们自己也是某种神秘 JIT。写代码时先用 perf/vtune 之类的东西查出性能热点，然后再优化跑得多的部分…… 为什么针对热点优化：阿姆达尔定律 FDO - Feadback-Directed Optimization之前我们已经知道了多层的 JIT 会分析运行的代码执行的情况，以确定何时对代码进行优化。 我们只收集 “代码在过去一段时间内运行次数” 这一个信息，就可以较好地确定代码需要的优化程度。但是我们在运行时对程序进行分析时，往往能得到更多的信息。比如，程序在某个分支失败的概率等等。而这些信息往往是无法在源代码中体现出来的。我们能不能利用这些信息来对代码做进一步的优化呢？ 这就是 FDO 的思路：利用代码运行时的收集的数据来优化代码。 在微软的文档里通常叫 PGO，Profile-Guided Optimization 很容易想到，借助 FDO 我们可以实现这几个神奇优化： 内联高频执行的函数 寄存器分配优化 条件跳转优化 还有一些不那么容易想到的优化： 虚函数调用优化：发现某个 virtual call 总是调一个函数，就加一组条件判断 + 直接调用来优化 同时，由于 FDO 是根据代码运行的实际数据来优化，所以它会更加容易适应实际数据的模式。这比 AOT 编译对着源代码瞎猜好多了…… JIT 中的 FDO 通常也分为两种，分别是： Sample-Based FDO：工作方式类似 perf(1)，原理是采样 Instrumentation-based FDO：工作方式类似 gprof(1)，原理是插桩 因为平时没写什么带 JIT 的脚本语言，所以这部分暂时没有例子。如果有人知道的话欢迎补充一些。 AOT - Ahead Of Time CompilationAOT，即 Aheaed Of Time。顾名思义，就是把程序提前编译好，整成二进制/字节码啥的，然后需要用的时候直接执行。在这期间，编译器 通常 会消耗大量计算资源对代码进行大量优化。不同 pass 的优化贯穿了整个代码生成的过程。 LTO - Link-Time Optimization微软把这个叫 LTCG，怪。 链接时优化，发生在汇编器之后，生成可执行文件之前。 大致思想是，在链接时把目标文件都读进内存里，接着把这些东西看成一个整体，进行激进的优化。 优点： 跨文件的函数内联、常量传播、死代码消除等等 跨编程语言优化，比如，可以优化 C 和 Rust 混写的代码。 可实现相同代码的折叠与消除（听起来有点像 zip 压缩的感觉？） 缺点： 冲浪时发现 有个文章 说相同函数的折叠在涉及到函数指针的比较操作时可能不安全，至于为什么我暂且蒙在鼓里…… 非常慢。我在编译 rust 代码时如果开了 lto = &quot;fat&quot;，要在链接那里等好久。 对策： 将内存中的巨大二进制代码分块，并行进行 LTO。不过并行度越高，同一个优化线程所看到的代码就越少，优化机会也就越少。所以这里还是涉及到编译速度和编译质量折衷的问题…… 具体到实现上的话，GCC 和 LLVM 不约而同（约了也说不定，反正大家都你偷我的我偷你的……）地选择了 bitcode 的形式。也就是说，开启 LTO 相关的编译选项后，生成的目标文件中将不再是机器码，而是编译器自己的 bitcode。至于为什么这样设计，官方文档说如果换用其他方案会产生工程复杂性等诸多问题，因为我没写过链接器，不太知道咋回事，所以也暂且蒙在鼓里。 同时，GCC 和 LLVM 各自又把 LTO 的过程划分成了好几个阶段，并不是一趟跑完的（所以才这么慢啊）。 FDO - Feadback-Directed Optimization上面讲 JIT 的时候就已经提到了 FDO，我们知道 FDO 是需要依靠代码运行时的信息来决定优化方式。这种优化似乎天生是适合 JIT 的，因为 JIT 在解释执行代码的时候就能自然地拿到很多关于程序运行情况的信息。 如果我们说，在 AOT 编译里面也能做 FDO 呢？ 以 MSVC 为例（他们会把这个操作叫 PGO），它的大概流程是： 先用一些魔法参数编译出一个可执行文件 运行这个可执行文件几次（称为 train run），它会自动收集运行信息并且写到某个文件里 另一些魔法参数，使编译器参考之前收集到的信息来编译出最终的可执行文件 LLVM 好像也有类似物，叫做 autofdo，由 Google 开发，有几页 简单介绍。但是我还没看完，懒狗程度令人感叹。 之前我们提到，JIT 里面的 FDO 有很多优化，比如： 内联高频执行的函数 寄存器分配优化 条件跳转优化 相比之下， AOT 的 FDO 还能做出更多神奇的优化，比如： 基本块优化：可以把经常执行的一些基本块放到同一个 page 里面 死代码隔离：把多次 train run 都没有使用的代码放一个独立的 section 里面，如果它们没真的没被运行，就不用给它们分配 page 了！ 错误处理代码隔离：同死代码隔离。 然而，在 AOT 上应用 FDO 还会有很多不可忽略的缺点： 编译模型十分复杂 大大增加编译时间 如果 train run 时使用的数据不够典型，甚至可能做出负优化 所以，目前 FDO 技术暂时还没有在 AOT 里面被广泛使用。 BOLT - Binary Optimization and Layout Tool似乎是 LLVM 专属的，目前还没有在别的地方找到类似物。仓库在 这里。 和 FDO 很像，也是基于运行时的信息来优化代码。不过和 FDO 不同之处在于，FDO 在产出可执行文件时需要根据收集到信息重新链接程序，而 BOLT 则是直接基于已有的可执行程序重建控制流等信息，接着调整整个程序布局。 由于不需要重新链接，BOLT 甚至可以对没有源码的库或者可执行程序优化。 非常科技。 吔我 AI 啦能不能用 AI 来帮我优化代码啊妈的 结束 快过年了，不要再讨论什么 AOT JIT 之类了。你写的各种离谱的 pass 和不知道怎么优化出来的代码回到家并不能给你带来任何实质性作用，朋友们兜里掏出一大把钱吃喝玩乐，你默默的在家里用各种晦涩难懂的语言和各种奇奇怪怪的技术优化出来的代码压根不对。亲戚朋友吃饭问你收获了什么你说我差点把图着色 RA 写出来了，亲戚们懵逼了，你还在心里默默嘲笑他们，笑他们不懂 Register Allocation，不懂 Local 和 Global 的区别，不懂 IR 除了 SSA 还能做 SoN，不懂一个 SSA 可以被你们玩出Hashed SSA，formal SSA，也笑他们根本不知道你的编译器的diagnosis都弄了个 TTY 真彩色 但实际上根本没人在意。你父母的同事都在说自己的子女一年的收获，儿子买了个房，女儿买了个车，姑娘升职加薪了，你的父母默默无言，说我的儿子整了个小电脑，天天黑框敲个烂代码天天对着笑，一天折腾那个 Lit 和 GTEST，破电脑开起来嗡嗡响，家里的电表转的是越来越快了，头上的头发越来越少了，人也越来越魔怔了 编译器越来越强了，以往很多的技巧（比如著名的 Duff’s Device）正在随着编译技术的发展而成为历史。 任何编译器做优化都需要足够的信息，比如，有了控制流图就可以做可达性分析，多了运行时得到的信息又可以做 FDO。 而人对自己正在面对的问题，知道的信息总会是比编译器多的。所以，你要把你知道的东西或显式（比如，likely() 和 unlikely）或隐式（比如，不用向后跳的 goto 以免破坏可规约性）地告诉编译器，让编译器来帮你完成复杂而繁琐的优化。 快进到和编译器双向奔赴然后结婚😋😋","link":"/2023/10/01/note/lto-plo/main/"},{"title":"Page&#x2F;Buffer Cache 是什么？","text":"Page/Buffer Cache 是什么？ 简介Page Cache 试图最小化磁盘 IO 本质上是一堆内存页面 内存页面（Page）：一小段连续内存，是操作系统管理内存的最小单位 包含了很多最近访问过的文件的内容 意思是不包括 inode、目录等东西！ 对于 inode 和目录来说，他们的 page cache 的类似物分别叫做 inode cache 和 directory entry cache。其中 directory entry cache 又由 inode cache 组织而来。 用途广泛，用于 file-backed mmap、buffered io，甚至 swap。 需要文件系统支持 Buffer Cache 试图最小化磁盘 IO 本质上是内存里的一堆块 块：操作系统对磁盘操作的基本单位，在 Linux 中要求大小为 2 的整数次幂，且比 sector 大，比 page 小 sector：磁盘读写数据的最小单位，由磁盘决定。 包含了最近访问过的块 用途不多，基本上只用来加速块设备 块设备（Block Device）：支持随机读写的设备。典型的比如磁盘。 不需要文件系统 比如，文件系统的 superblock 一般会躺在 buffer cache 里面 两者的关系可以参考下图（从 usenix 上面偷的）： 考古时间 为什么 page cache 是一堆内存页面，而 buffer cache 是一堆块呢？ 最开始 Linux 上面只有 buffer cache，此时 buffer cache 仅仅用于加速 buffered io 操作，向上与 read/write 交互，向下与磁盘交互。所以 buffer cache 设计成一堆块是很合适的。 page cache 则是为了支持 mmap，在 2.2 版本中引入的。由于它和内存关系比较紧密，所以设计成一堆内存页的形式。不过此时 buffered io 仍然只与 buffer cache 交互，不与 page cache 交互。要等两个 cache 合并之后才会出现大家所熟知的「调用 read/write 之后会写 page cache，过一会儿由操作系统把脏页写回磁盘」这种模式。 一些比较复杂的东西page cache 和 buffer cache 其实是一个东西？虽然逻辑上还是可以将他们分为两个东西，但是其实两者只是同一套数据的不同组织方式。 1234567+---------------------------------------+| page ||+-------+ +--------+ +--------++------+|||buffer1| | buffer2| |buffer3 ||buffer|||| | | | | || 4 |||+-------+ +--------+ +--------++------+|+---------------------------------------+ （没找到合适的图所以画了个） 每个 buffer 可以通过 buffer_head 结构体中的 b_page 字段获取自己对应的 page，同时 page 也可以通过 page 结构体中的 buffers 字段来得到自己所拥有的一组 buffer。 既然 page cache 与 buffer cache 合并了……那如果我在 A 进程对 /dev/sda1 上的一个文件 F 的一个连续区域做 shared mmap，再在 B 进程对 /dev/sda 本身做 shared mmap，两个进程映射的实际磁盘空间一致，那 A 进程与 B 进程能映射到同一个 page 吗？ 答案是不行 :3。因为 A 进程的 page 是文件系统给的，而 B 进程得到的东西更像是一堆 buffer 组合成的 page。 此时数据组织大概是这样的： 1234567891011121314151617+---------------------------------------+ +---------------------------------------+| A page | | B page || | | || | | || o o o o | | o o o o || | | | | | | | | | | |+----|---------|----------|-----------|-+ +---|-------+----------+---------+------+ v v v v | | | | +-------+ +--------+ +--------+ +------+ | | | |`|buffer1| | buffer2| |buffer3 | |buffer| | | | | | | | | | | | 4 | | | | | +---^---+ +---^----+ +---^----+ +--^---+ | | | | +---------+----------|-----------+--------+ | | | +----------|-----------+----------------+ | | +-----------+---------------------------+ | +---------------------------+---------+ 一些好玩的接口来点文件预读除了缓存已经读过/写过的数据之外，猜测程序要读什么从而提前把它们读进 page cache 中，也能加快程序！ posix_fadvise(2): POSIX_FADV_SEQUENTIAL 参数可以暗示内核自己将要顺序读文件。 madvise(2): MADV_SEQUENTIAL 参数可以暗示内核自己将顺序使用一些内存，配合 mmap(2) 使用。 readahead(2)：简单直接地告诉内核，偷偷多读一些东西（感觉这是个没用的屑调用……）。 掉落擦车可以通过 /proc/sys/vm/drop_caches 来告知内核扔掉一些 cache 数据。可以通过 echo X &gt; /proc/sys/vm/drop_caches 来使用。其中 X 的取值可以为 1, 2 或 3。当 X 为 1 时意思是让内核扔掉所有 page cache 里面的数据。2 和 3 代表什么，不知道 :3。 在测试一些 io-bounded 的程序时，为了防止 page cache 对测量结果造成干扰，可以在测试前运行一下。 未解之谜发现自己还是不太看得懂 free(1)。 12 total used free shared buff/cache availableMem: 13Gi 4.4Gi 3.2Gi 135Mi 6.5Gi 9.1Gi","link":"/2023/10/01/note/page-buffer-cache/main/"},{"title":"Perf 笔记","text":"Perf 笔记环境 Linux Syameimaru-Aya 5.17.0-2-amd64 #1 SMP PREEMPT Debian 5.17.6-1 (2022-05-11) x86_64 GNU/Linux。 配置环境首先安装 linux-perf 软件包，获得 perf(1) 应用程序。 接着运行 perf，发现报了奇怪的错误： 123456789101112131415161719:56 Syameimaru-Aya ~/sr/la/hpc/perf0 perf record -a ./a.outError:Access to performance monitoring and observability operations is limited.Consider adjusting /proc/sys/kernel/perf_event_paranoid setting to openaccess to performance monitoring and observability operations for processeswithout CAP_PERFMON, CAP_SYS_PTRACE or CAP_SYS_ADMIN Linux capability.More information can be found at 'Perf events and tool security' document:https://www.kernel.org/doc/html/latest/admin-guide/perf-security.htmlperf_event_paranoid setting is 3: -1: Allow use of (almost) all events by all users Ignore mlock limit after perf_event_mlock_kb without CAP_IPC_LOCK&gt;= 0: Disallow raw and ftrace function tracepoint access&gt;= 1: Disallow CPU event access&gt;= 2: Disallow kernel profilingTo make the adjusted perf_event_paranoid setting permanent preserve itin /etc/sysctl.conf (e.g. kernel.perf_event_paranoid = &lt;setting&gt;) 跟着报错提示里面提到的文档 Perf events and tool security 看了一圈，大概知道问题出在 perf 的安全措施上。文档里说，随意使用 perf 可能允许人获得其他人正在运行的程序中的数据，不安全。我用的发行版就默认配置成所有人都不能使用 perf 了。 文档给了一种多用户时控制权限，只让特定的人使用 perf 的做法：首先将 /usr/bin/perf 用 setcap(8) 程序加上 CAP_PERFMON CAP_SYS_PTRACE 两个标签，使 /usr/bin/perf 能够正常使用（没有 CAP_PERFMON 标签的应用程序无法调用 perf_event_open(2) 函数）。接着新建个用户组，仅使在那个组里的用户拥有 /usr/bin/perf 的可执行权限。这样对于一个不允许使用 perf 的人来说，外面偷来的 perf 会因为没有 CAP_PERFMON 而无法使用，自带的 /usr/bin/perf 则没有执行权限。整个设置避免了未经许可的人使用 perf 程序。 因为我的笔记本电脑肯定只有我一个用户，所以我非常暴力地改了一发，在 root 权限下往 /proc/sys/kernel/perf_event_paranoid 文件里写了个 -1。接着在 /etc/sysctl.conf 里加入一行 kernel.perf_event_paranoid = -1。 12root@Syameimaru-Aya:~/tmp# echo -1 &gt; /proc/sys/kernel/perf_event_paranoidroot@Syameimaru-Aya:~/tmp# 接着 perf 就可以正常运行了。 123456789101112131420:27 Syameimaru-Aya ~/sr/la/hpc/perf0 cat a.c#include &lt;stdio.h&gt;int main(void) { int i; for (i = 0; i &lt; 10000000; ++i) i + i; return 0;}20:27 Syameimaru-Aya ~/sr/la/hpc/perf0 gcc -O0 a.c &amp;&amp; perf record -a ./a.out[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.877 MB perf.data (104 samples) ] 获得炫酷火焰图中午午睡的时候梦到生成火焰图要用命令 perf script flamegraph。于是试了一下，发现不行。 1234567891020:29 Syameimaru-Aya ~/sr/la/hpc/perf0 perf script flamegraph------------------------------------------------------------perf_event_attr: size 128 { sample_period, sample_freq } 4000... 超级长的输出 ...Flame Graph template /usr/share/d3-flame-graph/d3-flamegraph-base.html does not exist. Please install the js-d3-flame-graph (RPM) or libjs-d3-flame-graph (deb) package, specify an existing flame graph template (--template PATH) or another output format (--format FORMAT). 啊报错说缺少包 libjs-d3-flame-graph。太良心了，连缺什么包都给提示好。显得我很笨的样子 :(。 12345620:33 Syameimaru-Aya ~/sr/la/hpc/perf0 i libjs-d3-flame-graphReading package lists... DoneBuilding dependency tree... DoneReading state information... DoneE: Unable to locate package libjs-d3-flame-graph 提示说包不存在。用 apt-file 找了下报错信息中提到的关键文件 /usr/share/d3-flame-graph/d3-flamegraph-base.html，发现源里没有这个东西。不过在 pkgs.org 上找了下发现 rpm 的包到是有……怀疑开发都写报错信息的时候只是把红帽系打包的命名习惯改成了 Debian 系的，估计根本就没看有没有这个包吧！ 最后用 alien(1p) 把 rpm 转成 deb 装上。成功运行。","link":"/2023/10/01/note/perf/main/"},{"title":"对集群上 df 和 du 命令显示结果不一致的排查记录","text":"对集群上 df 和 du 命令显示结果不一致的排查记录背景在集群上跑作业，然后把磁盘空间吃掉了。把占用空间很大的文件删掉后，du /home 命令的结果显示磁盘占用已经回到了正常水平，但是 df -h 显示，/home 所在分区的磁盘占用率还是 100%，也不能新建和修改文件。 猜想不会是把文件系统弄坏了吧！仔细想了想好像不可能，因为平时都是用普通用户的身份工作的……不太可能搞出影响文件系统的操作。 有些人的小文件太多，把 inode 给用光了！看起来有可能，但是回想下很久很久以前自己做赛博仓鼠的时候遇到的问题，就会发现两个问题表现完全不一样。 很久很久以前，赛博鼠鼠 jyi 试图往自己的鼠鼠洞里塞图片，发现没有磁盘空间了！他 df 了下，发现硬盘空间还有很多，但是新建文件就是会出错。他又试了试往已有的文件后面追加写入一些东西，好像可以成功。他觉得非常奇怪，“凭什么磁盘有空间，但是就是不让我放东西呢？” 用一种比较笨蛋的方法来看 ext{2,3,4} 文件系统，就知道文件系统中，一个文件需要 1 个 inode 和许多许多 block。其中，inode 用来存放文件的元数据，block 用来存放文件本身。由于 block 数量一般多于 inode 的数量（block 的数量少于 inode 的数量有啥用啊……），所以可能会出现 inode 耗尽，而 block 有剩余的情况。在这种情况下，无法新建文件，却可以修改文件。 因为赛博鼠鼠 jyi 非常菜，所以他与电脑搏斗了一番后才想起关于 inode 的知识。他 df -i 了一下，发现自己要存放图片的文件系统的 inode 已经用光了。最后他把一些图片打包成 sfs，再挂载到世界树目录树上，从而在原本的文件系统里回收了一些 inode，终于解决了这个问题。 回到集群上来，为什么这个表现和集群上遇到的状况完全不一样呢？因为经过检查发现，集群上显示 df -i 不是 100%，df -h 显示的使用率是 100%；而很久很久以前和自己的电脑搏斗时，df -i 显示的使用率是 100%，df -h 则是比 100 小不少的数字。 这说明集群上很可能不是很多小文件把 inode 用光的问题，更可能是巨大文件很简单地把 block 用光的问题。 有一些邪恶文件藏在了黑暗角落里！Linux 下面是可以往非空目录上挂载文件系统的，挂载后原目录里有的文件将会被遮盖掉。这些文件显然会被 df 统计，但是不会被 du 统计。 显然，最简单的方法就是把根目录之外的所有目录卸载，然后跑一下 df 和 du。然而，现在要操作的是运行中的系统（也许还有同学在上面跑神秘程序，那种中断了会遭遇线下真人快打的），不能这么粗暴地处理…… 最后我找了个 tmpfs /run/mnt（因为根目录下没法新建文件夹做挂载点了），然后 mount --bind / /run/mnt。接着进 /run/mnt 一看，发现 df 和 du 的结果仍然不同！仍然是 du 很少一点，df 巨大无比的结果。 破案正在自闭时，突然想起来，好像学文件系统时在懵懵懂懂的时候学到了 Linux 下 inode 结构体里，有关 i_count 和 i_nlink 的知识。其中，i_count 代表当前有多少个文件描述符引用了这个文件，i_nlink 代表这个文件在文件系统里有多少个硬链接。当且仅当 i_count 和 i_nlink 都为零时，这个 inode 和她所持有的 block 才被会释放。有没有这种可能，一个神秘邪恶，吃光了磁盘的巨大文件，它的 i_nlink 是 0 同时 i_count 非零，这样它不会被递归查看文件名的 du 找到，但是能被统计 block 的 df 给检查到呢？ 于是使用 lsof | grep deleted 一查，果然有一堆坏比 Perl 程序，打开了巨大文件没关。文件的所有者是我，大小有 780G。考虑到集群上好像只有我写 Perl，所以主谋是谁应该不言自明了…… 结局使用天火圣裁发动了一次牛逼的攻击……其实是 ps -u jyi，把自己所有的进程，不管好比还是坏比都干掉了。然后 df 了几次，看着可用空间逐渐上涨。 问题最终解决了，可喜可贺可喜可贺。另外给好朋友说这个事时，还听说在 “进程打开了文件，但是文件不小心删掉了” 这种情况下，在进程关闭之前，可以去 /proc/X/fd/Y 下面把文件找回来。其中 X 是进程 pid，Y 是软链接，名字就是文件描述符，目标是被打开的文件，用 cat 命令就可以把文件给找回来。利用的也是 inode 释放的机制。 总之，Linux 真神奇啊 :3","link":"/2023/10/01/note/running-process-constantly-consume-disk-space/main/"},{"title":"shell 初始化","text":"shell 初始化众所周知，shell 初始化是一坨巨大的不祥之物。但是如果不了解初始化的过程的话，可能会在编写各种 rc、crontab 时被折磨。所以分享让大家试吃一下。 基本概念login shelllogin shell 是个比较古老的概念，指由 logind 验证用户身份后，便提供一个 login shell 供用户工作。这个 shell 的特殊意义在于，它和用户的会话紧紧绑定在一起，在它开始运行前与它结束运行后都会往 /var/log/wtmp 写入用户的登录记录。除了它以外，所有的被用户手动运行的 shell 都被视作普通的应用程序。 因为大家现在都在 tty7 用各种基于 X 的登录管理器，它们验证用户身份后会提供一个桌面环境，所以 login shell 的概念没啥用了。但是它的一些历史遗留问题还是可能给大家带来困惑。 生成一个 login shell 有两种方法： 在 shell 后面加上 -l 参数，比如 bash -l。 比如，这是一个 login shell： 123403:18 Syameimaru-Aya ~0 bash -l03:18 Syameimaru-Aya ~0 logout 而这不是一个 login shell： 1234503:18 Syameimaru-Aya ~0 bash03:18 Syameimaru-Aya ~0 logoutbash: logout: not login shell: use `exit' 让 shell 的 argv[0] 以 - 开头。 我们在通过 ssh 远程登录，或者从 ttyN 用 logind 登录时都可以获得 login shell。显然 logind 和 ssh 不应当对 shell 的参数做出假设（即不能假设自己即将运行的程序有一个 -l 参数）。所以他们用改 argv[0] 的方式来通知 shell。 sshd 是这么干的的 ssh/session.c ： 12345/* * If we have no command, execute the shell. In this case, the shell * name to be passed in argv[0] is preceded by '-' to indicate that * this is a login shell. */ logind 也是这么干的（在 ttyN 里面试试这些东西）： 123456789101112131415Debian GNU/Linux bookworm/sid Syameimaru-Aya tty2Syameimaru-Aya login: jyiPassword:Linux Syameimaru-Aya 5.19.0-2-amd64 #1 SMP PREEMPT_DYNAMIC Debian 5.19.11-1 (2022-09-24) x86_64 GNU/LinuxThe programs included with the Debian GNU/Linux system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Fri Sep 30 03:06:30 CST 2022 on tty203:34 Syameimaru-Aya ~/tmp0 echo $0-bash interactive shell区分 interactive 与 non-interactive 的意义在于，让 shell 在给人类使用时与执行脚本时表现出不同的行为。 要求标准输入和标准输出都指向终端（用 isatty 系统调用确定）。仅在 interactive shell 里面会打印提示符，同时启用行编辑和 job control 特性，对人类十分友好！ 这也解释了为啥用 nc -l -p 2333 -e /bin/bash 搞的丐版远程登录非常难用，因为这不是 interactive shell，没有方便的编辑特性。也能解释为啥 echo echo hello | bash 不会输出提示符而是直接输出命令结果，因为这不是 interactive shell，不会输出提示符。 当然，也可以用 -i 选项暴力启动交互模式。 12345678903:42 Syameimaru-Aya ~0 echo echo hello | bash -i 03:43 Syameimaru-Aya ~ 0 echo hello hello 03:43 Syameimaru-Aya ~ 0 exit03:43 Syameimaru-Aya ~0 （为了分辨命令的输出，输出部分往右缩进了一些）。 此时 shell 会像正常一样输出提示符，读取输出并且执行。 不同的组合读取配置文件的区别以 bash 为例： login：首先是 /etc/profile，接着是 /etc/profile.d/*，最后是 ~/.bash_profile ~/.bash_login ~/.profile 三者按顺序检查，读取第一个可读的文件。（注意没有 ~/.bashrc）在 shell 退出时，还会读取 ~/.bash_logout。non-login：不会读取任何配置。interactive：依次读取 /etc/bash.bashrc ~/.bashrc。non-interactive：不会读取任何配置。 一般情况下，shell 启动时读取的配置是上列之一，并且 login 优先于 interactive。比如，如果 shell 以 login + interactive 的方式启动，则会读取 /etc/profile、/etc/profile.d/*、~/.bash_profile或~/.bash_login或~/.profile，但是并不会考虑 /etc/bash.bashrc 和 ~/.bashrc，即使这是一个 interactive shell。 有个仅用于 bash 的例外是，当其以 non-login 且 non-interactive 的方式启动时，它会检查名为 BASH_ENV 的环境变量。如果变量值所表示的文件存在，则会读取该文件作为配置。 这套神秘机制造成的麻烦~/.bashrc 与 ~/.bash_profile 之间的互动 login shell 不会读取 ~/.bashrc，这使得 login shell 不能读取一些配置，很难用。为了解决这个问题，人们决定在 ~/.bash_profile 里引用 ~/.bashrc 一些人会在 ~/.bashrc 里对命令加入一些保护措施，比如 alias rm='rm -I --preseve-root'，使得在同时删除三个以上文件时需要确认才能删除，另外，有些人可能会拿垃圾桶代替 rm。 一些脚本会以 login 的方式执行（通常是运行得非常早的脚本，甚至不能从父进程里继承 PATH），以保证自己能读取 /etc/profile，得到正确的环境变量。 当这三点齐聚时，会发生什么呢？ 安装软件包时，本来应该被彻底删除的临时文件被不明不白地扔进了垃圾箱里，占用不知道多少的空间。 即使用了 -y 参数来避免安装时的用户输出，仍然有可能因为 rm -I 等命令而需要等待输入。这对一些后台执行的脚本（比如定时自动更新）来说是非常坏的，因为很可能没有用户会来输入一个 y。 为了解决这个问题，只好在 ~/.bashrc 前面加上这一句看起来很像魔法咒语的指令： 1[[ $- == *i* ]] || return ……使得 bash 在读取 ~/.bashrc 当配置文件时，如果是非交互终端则立即停止读取。 crond 找不到命令，但是自己在终端里操作时又有为了方便描述，把这个命令叫作 lolcat 有些人喜欢把 lolcat 放在 ~/.local/bin/ 里 有些人写 crontab 时喜欢用 lolcat（？） 他在 ~/.bashrc 里面将 ~/.local/bin/ 加入到 PATH 中 crond 运行 shell 时为 non-interactive + non-login 模式 会发生什么呢？ 当在终端里试图运行 lolcat 时，因为现有的是 interactive + non-login 模式，所以读取了 ~/.bashrc，正确地设置了路径。 当在 crond 里运行 lolcat 时，因为是 non-interactive + non-login 模式，没有读取 ~/.bashrc，PATH 里没有 ~/.local/bin，找不到 lolcat 所以在写 crontab 时，只好写 bash -lc lolcat 不仅仅是 shell 脚本，C 中的 system()、Python 的 os.system() 以及更多类似物都会遇到这个问题。在终端里直接执行时，会从 bash 中继承 PATH，从而表现出正确的行为。而如果在 crond 内执行，则会出现找不到命令的问题。 更多例子暂时没遇到……","link":"/2023/10/01/note/shell-init/main/"},{"title":"urxvt 跑得比 alacritty 还快，为什么呢？","text":"urxvt 跑得比 alacritty 还快，为什么呢？答案答案是 urxvt 并没有老老实实地绘制其内程序输出的每一个字符，而是通过一些非常取巧的方法，减少了屏幕渲染的内容数量。 具体来说，是用了以下两个优化： jump scroll：如果短时间内需要渲染很多行，那么 urxvt 仅会在收到的行能充满一屏时尝试刷新。 skip scroll：在 jump scroll 的基础上，限制刷新率为 60 Hz。 开启这两个优化之后，urxvt 收到的很多内容实际上都被直接扔进历史记录里了，根本没在屏幕上出现过。同时，因为人的眼睛是非常低速的设备，所以即使这些内容没有在屏幕上出现，也不会影响使用体验。 如果禁用掉这些小优化，urxvt 的速度大概仅是 alacritty 的 1/2 到 1/3。 alacritty 与 urxvt 的简介urxvt 本身是个二十多年前的老东西，使用了很多奇怪的 X 特性。配置文件和 xterm 一样非常奇怪，可能是 Xorg 给世界留下的遗产之一……使用 C 和 C++ 编写，用 Perl 扩展。rxvt 的可扩展性很强，对标准支持也很好，各种 corner case 处理相对比较完善。 alacritty 是个很新的项目，号称要成为最快的终端。使用超级炒作语言 rust 开发，并且实现了 GPU 加速。他们一度声称自己是 “Fastest Terminal Emulator in Existence（现存最快终端）”。但是在 2020 年末的 一次提交 中不知道为什么他们换了说法，甚至连大家炒作时最爱的 “Blazing Fast” 也干没了。可能是开发者开发地表最速终端的梦想在现实里撞车了。非常快乐，大家快去围观。总之，相比项目早期的自述，现在的自述温和了很多。 两个都是非常好的终端。我之前是在 Windows 下用 alacritty，在 Linux 下用 urxvt。 为什么需要关注终端速度……其实意义也不是很大，因为大家在输出内容太长的时候都会 | less 一下，用 pager 分页来看，终端速度对使用体验的影响很小。 但是既然速度是个能比的项目，那总会有人抱着一种宝可梦对决的心态来研究两个终端谁快谁慢，这也促进了这篇水帖的诞生！ urxvt 的小优化相关代码摘自 urxvt 代码仓库 src/command.C 的第 2267 行。 if (ecb_unlikely (ch == C0_LF || str &gt;= eol)) { if (ch == C0_LF) nlines++; refresh_count++; if (!option (Opt_jumpScroll) || refresh_count &gt;= nrow - 1) { refresh_count = 0; if (!option (Opt_skipScroll) || ev_time () &gt; ev::now () + 1. / 60.) { refreshnow = true; ch = NOCHAR; break; } } 大概就是它用一堆错综复杂的条件变量实现了上面提到的小优化，整段代码唯一的注释的是这样的： /* * If there have been a lot of new lines, then update the screen * What the heck we'll cheat and only refresh less than every page-full. * if skipScroll is enabled. */ 摆了。这啥 GNU-style 的神秘老代码看得我头疼……","link":"/2023/10/01/note/urxvt-jump-skip-scroll/main/"},{"title":"markdown 中使用图片但是不使用图床","text":"markdown 中使用图片但是不使用图床起因是写博客要插入图片，但是懒得上传图片到图床。经过一番尝试后发现可以把图片 base64 编码后放进 markdown 语法中本应该放图片 url 的位置，直接将图片插进 markdown 文件里。 显然我们需要找出 markdown 中的图片。为了减少图片大小，还需要缩放和压缩。为了偷懒想找找有没有相关的项目可以实现功能。只找到了 markdownImage。但是这个图片压缩好像是调用一些网站的 api 来完成相关功能的，还有免费次数限制，并且并不提供图片缩放功能。感觉和需求出入有点大…… 最后我写了个便利脚本来完成这项任务，需要机器上安装了 imagemagick、base64 和 tr。 （这个脚本问题还是比较多，比如没有区分代码块里格式类似图片链接的部分和真正的图片链接，某些情况，比如 markdown 教程估计会锅掉。但是总之还是能用的嘛） 会从标准输入和命令行文件中读取内容，处理后输出到标准输出。（在后面接一个 clip 剪贴板程序就可以直接准备发布到博客园啦） 12345678910111213141516171819202122232425262728#!/usr/bin/env perluse v5.12;sub process_image{ $_ = shift; if (/\\.gif$/) { &quot;data:image/gif;base64,&quot; . qx { convert -fuzz 15% -layers Optimize \\Q$_\\E - | base64 | tr -d '\\n' } } else { &quot;data:image/jpeg;base64,&quot; . qx { convert -resize \\Q1280x960&gt;\\E -strip -quality 75% \\Q$_\\E jpeg:- | base64 | tr -d '\\n' } }}while (defined(my $line = &lt;&gt;)) { for ($line =~ /!\\[[^\\]]*\\]\\([^)]*\\)/g) { my ($mark, $desc, $file) = /(!\\[([^\\]]*)\\]\\(([^)]*)\\))/; $file = process_image $file; $line =~ s/\\Q$mark\\E/![$desc]($file)/; } print $line;}","link":"/2023/10/01/tutorial/blog-image/main/"},{"title":"使用 complete-alias 补全 bash 别名的参数","text":"使用 complete-alias 补全 bash 别名的参数命令别名众所周知，bash 中有个很方便的功能，使用 alias 命令创建命令别名。比如： 123456789101112# Gitalias cg='cd `git rev-parse --show-toplevel || echo .`'alias gaA='git add -A'alias gad='git add'alias gbc='git branch'alias gcm='git commit'alias gco='git checkout'alias gst='git status'alias gcl='git clone'alias glg='git log --graph'alias gmg='git merge'alias gdf='git diff' 这样，如果我们输入 gcl，bash 就会认为我们输入的是 git clone。极大地减少了输入字母的数量。 命令参数补全bash 还有另一个强大的功能，命令参数补全。这个命令参数补全不仅仅是补全当前目录下的文件，而是根据当前已经输入的命令和参数，猜测补全下一个参数。一般来说发行版都会提供大量写好的补全脚本，可以直接使用。 以 Debian 为例，安装 bash-completion 软件包后，在 ~/.bashrc 中加上 source /etc/bash_completion。接着输入命令，连续按下两下 tab 键就可以触发补全功能（按下 tab 键的地方在下面用 &lt;TAB&gt; 表示： 1234% 19:50:08 (master) ~/sr/md/bl/note/complete-alias0 ls --h&lt;TAB&gt;&lt;TAB&gt;--help --hide-control-chars --hyperlink--hide= --human-readable 虽然说没有 zsh 的好用就是啦。 但是有一个小问题bash 的命令参数补全是根据命令名来确定的，举一个简单的例子： 1234567891011121314_id(){ local cur prev words cword _init_completion || return if [[ $cur == -* ]]; then local opts=$(_parse_help &quot;$1&quot;) [[ $opts ]] || opts=&quot;-G -g -u&quot; # POSIX fallback COMPREPLY=($(compgen -W &quot;$opts&quot; -- &quot;$cur&quot;)) else COMPREPLY=($(compgen -u &quot;$cur&quot;)) fi} &amp;&amp; complete -F _id id 这是从 /usr/share/bash-completion/completions/id 里面摘抄的补全相关代码。可以看到，代码里先实现了 shell 函数 _id，再用 complete -F _id id 来把 id 命令相关的补全和 _id 绑定在一起。即需要补全 id 命令的参数时，会用某种方式调用 _id 函数。 这样确实可以处理很多情况，但是对别名无效。比如我们运行 alias gco='git checkout'，把 gco 作为 git checkout 的别名。当我们输入 gco 再按 tab 键时，因为没有绑定 gco 相关的补全函数，所以 bash 不知道如何补全，只能在后面接上文件名。 我们期待的行为应该是输入 gco 再按 tab 就和输入 git checkout 再按 tab 一样，可以补全出分支名称： 123% 20:03:23 (master) ~/sr/md/bl/note/complete-alias0 git checkout&lt;TAB&gt;&lt;TAB&gt;HEAD linux-csharp-build master ORIG_HEAD 小问题解决了之前肯定也有人遇到过一样的问题，并且造了相关的轮子。这儿有一个好用的：complete-alias。 我们只要把仓库里面 complete_alias 文件中的内容复制下来，贴到 ~/.bashrc 尾巴上（有 1000 多行，有点野蛮。讲究的人可以把它放到某个目录里然后 .bashrc 里面用 source 命令处理？），再把最后一行 #complete -F _complete_alias &quot;${!BASH_ALIASES[@]}&quot; 前面的井号 # 删掉就算配置完成。重新启动 bash 即可使用。 总而言之挺开箱即用的，配置不费劲。 效果： 123% 20:14:27 (master) ~/sr/md/bl/note/complete-alias0 gco&lt;TAB&gt;&lt;TAB&gt;HEAD linux-csharp-build master ORIG_HEAD","link":"/2023/10/01/tutorial/complete-alias/main/"},{"title":"用盲文字符来在终端画黑白图像","text":"用盲文字符来在终端画黑白图像食用提示如果这篇文章在您的设备上显示很多方框，或许是字体出了问题。请确保自己使用的字体可以正常显示盲文。 在我的设备上，无论怎么操作都无法使 urxvt （rxvt ， xterm ） 表现出我想要的样子。因此在不建议您进行实验时使用 urxvt （rxvt ， xterm ） 。 想法来源有一天发现盲文就是一堆像素点，就想着用盲文文字在终端画图。 实现效果 分析12345678910111213141516⠀⠁⠂⠃⠄⠅⠆⠇⠈⠉⠊⠋⠌⠍⠎⠏⠐⠑⠒⠓⠔⠕⠖⠗⠘⠙⠚⠛⠜⠝⠞⠟⠠⠡⠢⠣⠤⠥⠦⠧⠨⠩⠪⠫⠬⠭⠮⠯⠰⠱⠲⠳⠴⠵⠶⠷⠸⠹⠺⠻⠼⠽⠾⠿⡀⡁⡂⡃⡄⡅⡆⡇⡈⡉⡊⡋⡌⡍⡎⡏⡐⡑⡒⡓⡔⡕⡖⡗⡘⡙⡚⡛⡜⡝⡞⡟⡠⡡⡢⡣⡤⡥⡦⡧⡨⡩⡪⡫⡬⡭⡮⡯⡰⡱⡲⡳⡴⡵⡶⡷⡸⡹⡺⡻⡼⡽⡾⡿⢀⢁⢂⢃⢄⢅⢆⢇⢈⢉⢊⢋⢌⢍⢎⢏⢐⢑⢒⢓⢔⢕⢖⢗⢘⢙⢚⢛⢜⢝⢞⢟⢠⢡⢢⢣⢤⢥⢦⢧⢨⢩⢪⢫⢬⢭⢮⢯⢰⢱⢲⢳⢴⢵⢶⢷⢸⢹⢺⢻⢼⢽⢾⢿⣀⣁⣂⣃⣄⣅⣆⣇⣈⣉⣊⣋⣌⣍⣎⣏⣐⣑⣒⣓⣔⣕⣖⣗⣘⣙⣚⣛⣜⣝⣞⣟⣠⣡⣢⣣⣤⣥⣦⣧⣨⣩⣪⣫⣬⣭⣮⣯⣰⣱⣲⣳⣴⣵⣶⣷⣸⣹⣺⣻⣼⣽⣾⣿ 这是 UTF-8 中的盲文字符。共有 256 个。每个盲文字符都由数个点组成。点最多的盲文字符（右下角）有 8 个点，它看起来像个实心黑框框；点最少的盲文字符有 0 个点（左上角），虽然它看上去像个空格，但它真的和空格不是一个东西。 稍微观察可以发现，一个盲文字符可以当成 4x2 的小形位图使用，如果能够良好组织，使盲文字符按某种方式排列，就可以拼出大一些的位图。 不同的 4x2 位图共有 2^8 = 256 个，而不同的盲文字符正好也有 256 个。这意味着盲文字符和 4x2 的位图之间有着一一对应的关系。为了方便盲文与位图的与相转化，我们需要设计一种编码方案。 上面列出的表显然是经过良好组织的，可以发现盲文字符的排布很有规律。找规律的过程略去不提，这里仅说编码方案。经过以下操作后，可以保证盲文字符和其对应的 4x2 位图有相同的编号： 盲文：将上表中的盲文从上到下，从左到右依次编号 0 到 255 。 位图：考虑搞一张权值表： 12341 82 164 3264 128 将表中所有对应位图黑色位置的权值加起来，得到的和即为位图的编号。 例如，字符 “⢫” ，其编号为 171 ，其位图为： 12341 11 00 10 1 和权值表 py 后得到 1 + 8 + 2 + 32 + 128 = 171 ，和期待结果一致。 使用这个方法，可以将 4x2 的小位图和它所对应的盲文字符的编号对应起来。于是，我们就可以在终端画图了。 实现首先对盲文字符打表： 123456789101112131415161718192021const char *magic_table[] = { &quot;⠀&quot;, &quot;⠁&quot;, &quot;⠂&quot;, &quot;⠃&quot;, &quot;⠄&quot;, &quot;⠅&quot;, &quot;⠆&quot;, &quot;⠇&quot;, &quot;⠈&quot;, &quot;⠉&quot;, &quot;⠊&quot;, &quot;⠋&quot;, &quot;⠌&quot;, &quot;⠍&quot;, &quot;⠎&quot;, &quot;⠏&quot;, &quot;⠐&quot;, &quot;⠑&quot;, &quot;⠒&quot;, &quot;⠓&quot;, &quot;⠔&quot;, &quot;⠕&quot;, &quot;⠖&quot;, &quot;⠗&quot;, &quot;⠘&quot;, &quot;⠙&quot;, &quot;⠚&quot;, &quot;⠛&quot;, &quot;⠜&quot;, &quot;⠝&quot;, &quot;⠞&quot;, &quot;⠟&quot;, &quot;⠠&quot;, &quot;⠡&quot;, &quot;⠢&quot;, &quot;⠣&quot;, &quot;⠤&quot;, &quot;⠥&quot;, &quot;⠦&quot;, &quot;⠧&quot;, &quot;⠨&quot;, &quot;⠩&quot;, &quot;⠪&quot;, &quot;⠫&quot;, &quot;⠬&quot;, &quot;⠭&quot;, &quot;⠮&quot;, &quot;⠯&quot;, &quot;⠰&quot;, &quot;⠱&quot;, &quot;⠲&quot;, &quot;⠳&quot;, &quot;⠴&quot;, &quot;⠵&quot;, &quot;⠶&quot;, &quot;⠷&quot;, &quot;⠸&quot;, &quot;⠹&quot;, &quot;⠺&quot;, &quot;⠻&quot;, &quot;⠼&quot;, &quot;⠽&quot;, &quot;⠾&quot;, &quot;⠿&quot;, &quot;⡀&quot;, &quot;⡁&quot;, &quot;⡂&quot;, &quot;⡃&quot;, &quot;⡄&quot;, &quot;⡅&quot;, &quot;⡆&quot;, &quot;⡇&quot;, &quot;⡈&quot;, &quot;⡉&quot;, &quot;⡊&quot;, &quot;⡋&quot;, &quot;⡌&quot;, &quot;⡍&quot;, &quot;⡎&quot;, &quot;⡏&quot;, &quot;⡐&quot;, &quot;⡑&quot;, &quot;⡒&quot;, &quot;⡓&quot;, &quot;⡔&quot;, &quot;⡕&quot;, &quot;⡖&quot;, &quot;⡗&quot;, &quot;⡘&quot;, &quot;⡙&quot;, &quot;⡚&quot;, &quot;⡛&quot;, &quot;⡜&quot;, &quot;⡝&quot;, &quot;⡞&quot;, &quot;⡟&quot;, &quot;⡠&quot;, &quot;⡡&quot;, &quot;⡢&quot;, &quot;⡣&quot;, &quot;⡤&quot;, &quot;⡥&quot;, &quot;⡦&quot;, &quot;⡧&quot;, &quot;⡨&quot;, &quot;⡩&quot;, &quot;⡪&quot;, &quot;⡫&quot;, &quot;⡬&quot;, &quot;⡭&quot;, &quot;⡮&quot;, &quot;⡯&quot;, &quot;⡰&quot;, &quot;⡱&quot;, &quot;⡲&quot;, &quot;⡳&quot;, &quot;⡴&quot;, &quot;⡵&quot;, &quot;⡶&quot;, &quot;⡷&quot;, &quot;⡸&quot;, &quot;⡹&quot;, &quot;⡺&quot;, &quot;⡻&quot;, &quot;⡼&quot;, &quot;⡽&quot;, &quot;⡾&quot;, &quot;⡿&quot;, &quot;⢀&quot;, &quot;⢁&quot;, &quot;⢂&quot;, &quot;⢃&quot;, &quot;⢄&quot;, &quot;⢅&quot;, &quot;⢆&quot;, &quot;⢇&quot;, &quot;⢈&quot;, &quot;⢉&quot;, &quot;⢊&quot;, &quot;⢋&quot;, &quot;⢌&quot;, &quot;⢍&quot;, &quot;⢎&quot;, &quot;⢏&quot;, &quot;⢐&quot;, &quot;⢑&quot;, &quot;⢒&quot;, &quot;⢓&quot;, &quot;⢔&quot;, &quot;⢕&quot;, &quot;⢖&quot;, &quot;⢗&quot;, &quot;⢘&quot;, &quot;⢙&quot;, &quot;⢚&quot;, &quot;⢛&quot;, &quot;⢜&quot;, &quot;⢝&quot;, &quot;⢞&quot;, &quot;⢟&quot;, &quot;⢠&quot;, &quot;⢡&quot;, &quot;⢢&quot;, &quot;⢣&quot;, &quot;⢤&quot;, &quot;⢥&quot;, &quot;⢦&quot;, &quot;⢧&quot;, &quot;⢨&quot;, &quot;⢩&quot;, &quot;⢪&quot;, &quot;⢫&quot;, &quot;⢬&quot;, &quot;⢭&quot;, &quot;⢮&quot;, &quot;⢯&quot;, &quot;⢰&quot;, &quot;⢱&quot;, &quot;⢲&quot;, &quot;⢳&quot;, &quot;⢴&quot;, &quot;⢵&quot;, &quot;⢶&quot;, &quot;⢷&quot;, &quot;⢸&quot;, &quot;⢹&quot;, &quot;⢺&quot;, &quot;⢻&quot;, &quot;⢼&quot;, &quot;⢽&quot;, &quot;⢾&quot;, &quot;⢿&quot;, &quot;⣀&quot;, &quot;⣁&quot;, &quot;⣂&quot;, &quot;⣃&quot;, &quot;⣄&quot;, &quot;⣅&quot;, &quot;⣆&quot;, &quot;⣇&quot;, &quot;⣈&quot;, &quot;⣉&quot;, &quot;⣊&quot;, &quot;⣋&quot;, &quot;⣌&quot;, &quot;⣍&quot;, &quot;⣎&quot;, &quot;⣏&quot;, &quot;⣐&quot;, &quot;⣑&quot;, &quot;⣒&quot;, &quot;⣓&quot;, &quot;⣔&quot;, &quot;⣕&quot;, &quot;⣖&quot;, &quot;⣗&quot;, &quot;⣘&quot;, &quot;⣙&quot;, &quot;⣚&quot;, &quot;⣛&quot;, &quot;⣜&quot;, &quot;⣝&quot;, &quot;⣞&quot;, &quot;⣟&quot;, &quot;⣠&quot;, &quot;⣡&quot;, &quot;⣢&quot;, &quot;⣣&quot;, &quot;⣤&quot;, &quot;⣥&quot;, &quot;⣦&quot;, &quot;⣧&quot;, &quot;⣨&quot;, &quot;⣩&quot;, &quot;⣪&quot;, &quot;⣫&quot;, &quot;⣬&quot;, &quot;⣭&quot;, &quot;⣮&quot;, &quot;⣯&quot;, &quot;⣰&quot;, &quot;⣱&quot;, &quot;⣲&quot;, &quot;⣳&quot;, &quot;⣴&quot;, &quot;⣵&quot;, &quot;⣶&quot;, &quot;⣷&quot;, &quot;⣸&quot;, &quot;⣹&quot;, &quot;⣺&quot;, &quot;⣻&quot;, &quot;⣼&quot;, &quot;⣽&quot;, &quot;⣾&quot;, &quot;⣿&quot;}; 接着实现 canvas 结构体。这里用 unsigned char 数组当成 bool 数组使用。日后优化时，可以用 bitmap 节省空间。 1234567891011121314151617181920212223typedef struct canvas { int width; int height; void *buf;} canvas;int canvas_init(canvas *p, int width, int height){ width = ((width - 1) / 2 + 1) * 2; height = ((height - 1) / 4 + 1) * 4; p-&gt;width = width; p-&gt;height = height; p-&gt;buf = malloc(sizeof(unsigned char) * width * height); if (p-&gt;buf == NULL) return 1; return 0;}void canvas_clear(canvas p){ free(p.buf);} 实现画像素点和打印功能： 123456789101112131415161718192021222324252627282930313233void canvas_draw(canvas p, int x, int y){ ((unsigned char (*)[p.width])p.buf)[y][x] = 1;}void canvas_erase(canvas p, int x, int y){ ((unsigned char (*)[p.width])p.buf)[y][x] = 0;}int canvas_test(canvas p, int x, int y){ return ((unsigned char (*)[p.width])p.buf)[y][x];}void canvas_print(canvas p){ int i, j, k, l; for (i = p.height; i &gt; 0; i -= 4) { for (j = 0; j &lt; p.width; j += 2) { int id = 0; for (l = 1; l &gt;= 0; --l) for (k = 3; k &gt;= 1; --k) id = (id &lt;&lt; 1) | canvas_test(p, j + l, i - k); if (canvas_test(p, j, i - 4)) id += 64; if (canvas_test(p, j + 1, i - 4)) id += 128; printf(&quot;%s&quot;, magic_table[id]); } putchar('\\n'); }} 实现完成。以下是函数功能与参数说明： 123456int canvas_init(canvas *p, int width, int height); 将 p 初始化为宽 width 高 height 的画布void canvas_clear(canvas p); 销毁画布 pvoid canvas_draw(canvas p, int x, int y); 在 p 的 (x, y) 位置画上一个像素点void canvas_erase(canvas p, int x, int y); 擦除 p 中 (x, y) 位置上的像素点int canvas_test(canvas p, int x, int y); 返回 p 中 (x, y) 上是否已经画过void canvas_print(canvas p); 打印 p 实现示例中的效果用 ImageMagick 的 convert 命令将图片文件转为只有 2 种颜色的 xpm 文件，写个傻瓜 xpm 解析器，配合上面的代码简单处理即可得到示例中的效果。傻瓜解析器的代码见：doxpm.c 。 在本机上，实现示例效果的命令为： 12345$ convert -colors 2 sample.png a.xpm$ gcc doxpm.c -o doxpm$ ./doxpm$ # 如果需要彩色的话：$ ./doxpm | lolcat 完代码仅被用来说明想法，并没有想写成一个可用的库。所以码风略快糙猛请多包涵。 感谢 zrz_orz 同学教我在洛谷日报上投稿，并提出大量修改意见。","link":"/2023/10/01/tutorial/canvas/main/"},{"title":"hyperfine 使用指南","text":"hyperfine 使用指南简介测量程序运行耗时是一个常见的需求。 我们经常会调整自己编写的程序，来给程序加速。但是自己提出的加速计划，不一定会被机器认可。比如，你觉得 ++i 比 i++ 更快并且花了两天时间把程序里所有的后缀全改成了前缀，但是机器不管，她编译的时候直接把你的写法给扬掉了。这个时候再在 git的提交信息里写 perf: 优化 XX 部分性能 就会显得非常滑稽。所以，我们经常需要对程序性能测试来保证自己的优化是有效的。对程序性能测试的最常用的方法就是计时。 小时候幼儿园的老师经常教育我们，在 bash 里面用 time 的命令就可以测量程序运行的时间。这也是大家最常用的方法。但是我们都知道，time 是一个非常粗糙的工具。用它测量程序性能时，总会遇到这么几个问题： 测量出来的时间真的是准的吗？会不会受到系统波动的影响？ 测量出来的时间有多可靠？该怎么知道测量误差？ 我能比较轻松地对比两个或多个程序的性能吗？ 我们可以通过写一堆土制脚本来解决上述问题，但是与其费心写功能不全、漏洞百出的脚本，还不如直接使用已有的趁手工具。 hyperfine 就是一个优秀的性能测试工具。 优势根据 hyperfine 自己的 介绍 ，hyperfine 拥有如下功能： 多次测量并统计均值方差 支持任意 shell 命令 进度条和预估剩余时间 预热：正式测试之前先运行几次 测试之前执行指定命令（可用于清除缓存） 自动发现 cache 影响和系统性能波动影响 多种输出格式，支持 CSV、JSON、Markdown 等等 跨平台 （注：hyperfine 的介绍是有 中文翻译 的，但是我看的时候它略微有些过时了。希望有好心人来更新一下翻译） 它的使用截图如下： 个人评测：life-changing 的好东西，我现在没有 hyperfine 都不会测程序了。 基本使用hyperfine 的使用方式非常符合直觉，命令行结构和选项设计得很好。 安装hyperfine 是用 rust 写的（不打算去学一下？）。如果机器上有 rust 开发环境，直接运行 cargo install hyperfine 即可完成安装。cargo 是 rust 的编译系统和依赖管理工具。 如果机器上没有 rust 开发环境，可以求助你的包管理器，或者从hyperfine 在 Github 上的发布页面 中，下载与自己的机器架构对应的二进制文件。 测试单个程序命令： hyperfine 'hexdump file' 结果： 11:17 jyi-station ~/tmp/bgifile 0 hyperfine 'hexdump test13.c' Benchmark 1: hexdump test13.c Time (mean ± σ): 385.0 ms ± 5.1 ms [User: 383.0 ms, System: 2.1 ms] Range (min … max): 381.6 ms … 398.9 ms 10 runs 从结果可以看出，hyperfine 把程序运行了 10 次。测量出来平均耗时是 385 ms，误差是 5.1 ms。运行的时候，hyperfine 把程序的所有输出重定向到了 /dev/null 里，所以终端上没有多余的内容。 你看，我几乎什么都没做，只是把命令提供给 hyperfine，她就自动帮忙把所有东西都测好了！ 我们甚至无需检查误差是否过大，因为 hyperfine 会自动检测误差过大的情况，并且根据程序运行时间的特征来猜测可能发生了什么问题，并给出一些建议。非常贴心。后面会详细讨论这些细节。 对比测试多个程序命令： hyperfine 'hexdump test13.c' 'xxd test13.c' 'xxd test14.c' 结果： 11:24 jyi-station ~/tmp/bgifile 0 hyperfine 'hexdump test13.c' 'xxd test13.c' 'xxd test14.c' Benchmark 1: hexdump test13.c Time (mean ± σ): 383.6 ms ± 1.9 ms [User: 381.8 ms, System: 1.6 ms] Range (min … max): 381.6 ms … 387.7 ms 10 runs Benchmark 2: xxd test13.c Time (mean ± σ): 90.2 ms ± 1.0 ms [User: 88.4 ms, System: 1.9 ms] Range (min … max): 88.7 ms … 93.4 ms 32 runs Benchmark 3: xxd test14.c Time (mean ± σ): 180.2 ms ± 2.8 ms [User: 176.8 ms, System: 3.2 ms] Range (min … max): 177.1 ms … 186.6 ms 16 runs Summary 'xxd test13.c' ran 2.00 ± 0.04 times faster than 'xxd test14.c' 4.25 ± 0.05 times faster than 'hexdump test13.c' 在这个例子里，我们给了 hyperfine 三个参数，让她测量三个程序的耗时。hyperfine首先输出了三个程序各自的运行结果，这部分和测试单个程序时的结果差不多。但是在报告的最后，hyperfine 还额外给出了一些信息。她指出了跑的最快的程序（港记程序 :P），并且显示了其相对其他程序的加速比和误差。 我们一般测试程序时只需要关注最后的 “Summary” 一栏，知道哪个更快、快多少就可以了。前面几行是和别人吵架时，给他们看测试结果让他们闭嘴时用的。 运行原理对每个程序，hyperfine 会把它运行 10 次（运行次数有选项可以配置）。hyperfine 会对运行时间计时，并且求出均值和标准差。 每次运行的时候，hyperfine 会运行一个 shell 来执行这些程序。比如，假定程序是 sleep 1，那么 hyperfine 实际运行的是 sh -c 'sleep 1'。这种用 shell 来运行程序的行为，会导致程序运行时间测量结果偏大；但是如果不用 shell 来运行程序，大家平时习惯的 ~/ 和 *.txt 这些便利缩写就不能用了，非常麻烦。 总之，这种使用 shell 来执行参数的设计，算是便利与准确之间的一种折衷。 为了使测量结果更精确，你可以手动禁止 hyperfine 使用 shell 来执行程序的行为。hyperfine 本身也会检测 shell 对测量结果的影响，并且在她觉得 shell 对测量结果的影响已经大到不可忽略时提出警告。判定规则与细节将在之后描述。 使用进阶现在，你已经基本学会用 hyperfine 了！让我们来看看一些更好玩的东西吧。 测试 IO 密集型程序假设我们要运行一个大量读写磁盘文件的程序 10 次，我们会发现什么怪现象呢？我们会发现，第一次或前几次运行所花费的时间会显著大于后面几次。这是由于 Linux 系统有 Page Cache 的机制，它会尽可能努力地把最近使用过的文件缓存在内存里。 在第一次运行的时候，程序试图读文件。操作系统发现内存里没有相关文件，只好老老实实地从磁盘上把文件读出来再交给程序。但是紧接着程序运行第二三四次，程序试图读文件时，操作系统发现文件刚刚才被读过，还被缓存在内存里，于是直接把内存中的内容交给程序，直接省略掉了读盘的过程。众所周知，内存的读写速度一般远大于硬盘。这导致了第二三四次运行程序时，程序用时会显著少于第一次。 类似的情况还会出现在很多具有缓存机制的系统（没有特指操作系统！）里。在对于这些系统打交道的程序计时时，我们需要给 hyperfine 加一些参数。 预热我们可以使用 --warmup N 的参数让程序被真正计时之前，先运行 N 次，其中 N 是一个整数。比如，hyperfine --warmup 2 sleep 3 这个命令实际上会运行 sleep 3 这个命令 12 次，其中最后 10 次会被计时。 这种方式有利于将程序需要用到的东西提前装到缓存里。可以测量程序在缓存工作良好时的运行效率。 提前执行指令我们可以使用 --prepare X 的参数让 hyperfine 每次运行程序之前，先运行一下 X，其中 X 是一条 shell 命令。比如，hyperfine --prepare 'echo 3 | sudo tee /proc/sys/vm/drop_caches' sleep 3这个命令，会运行 sleep 3 10 次，但是每次运行前，会运行echo 3 | sudo tee /proc/sys/vm/drop_caches 一次，来清除 Linux 的 Page Cache。 这种方式直接让缓存没用了。可以测量程序冷启动的速度。 测试运行时间过短的程序之前说到，hyperfine 会用一个 shell 来执行待计时的程序。但是如果程序跑得很快，导致 shell 启动、解析、执行的时间已经占总用时不小的一部分了，那么测量误差就会变得不可接受。 这个时候我们就可以使用 -N 参数来制止 hyperfine 使用 shell。此时，她会用一个内置的简陋的解析器来把命令的可执行文件和参数给分开。这个简陋的解析器主要使用空白字符来分割参数，但是也支持基础的转义字符和引号。 比如： hyperfine -N 'touch x' 不知道自己的程序属于哪种类型？有笨比…… 如果你不知道你的程序要跑多久，也不知道它是不是要用到某种缓存系统，直接把它当成纯计算的程序来测就行了。hyperfine 会在发现不对劲时来提醒你。 下面是几个例子： 奇怪的测量结果20:21 jyi-station ~/tmp/bgifile 0 hyperfine 'cat test18.c' Benchmark 1: cat test18.c Time (mean ± σ): 16.9 ms ± 1.0 ms [User: 1.1 ms, System: 15.9 ms] Range (min … max): 15.7 ms … 22.1 ms 154 runs Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options. hyperfine 发现测试的时候，有些数据与别的明显不在一个等级。所以她警告你并且建议你在系统闲的时候重跑。 初次测量很慢20:21 jyi-station ~/tmp/bgifile 0 hyperfine 'cat test19.c' Benchmark 1: cat test19.c Time (mean ± σ): 34.3 ms ± 14.1 ms [User: 2.2 ms, System: 31.8 ms] Range (min … max): 30.4 ms … 105.4 ms 28 runs Warning: The first benchmarking run for this command was significantly slower than the rest (105.4 ms). This could be caused by (filesystem) caches that were not filled until after the first run. You should consider using the '--warmup' option to fill those caches before the actual benchmark. Alternatively, use the '--prepare' option to clear the caches before each timing run. 这次 hyperfine 不仅发现数据异常，还发现是第一次跑的时候数据异常。于是她猜测是某种神秘的缓存系统起了作用，并且建议你用 --warmup 参数或 --prepare 参数来消除缓存的影响。 程序跑得很快20:21 jyi-station ~/tmp/bgifile 0 hyperfine 'cat test1.c' Benchmark 1: cat test1.c Time (mean ± σ): 0.9 ms ± 0.1 ms [User: 0.7 ms, System: 0.4 ms] Range (min … max): 0.7 ms … 1.3 ms 1340 runs Warning: Command took less than 5 ms to complete. Note that the results might be inaccurate because hyperfine can not calibrate the shell startup time much more precise than this limit. You can try to use the `-N`/`--shell=none` option to disable the shell completely. 这次，hyperfine 发现程序跑得很快，误差会比较大，并且建议你用 -N 参数来直接运行程序，绕过启动 shell 的步骤。 额外的功能除此之外，hyperfine 还有一些别的功能，比如参数化测试之类的东西。不过我感觉要参数化的话与其用这一坨命令行参数，不如去写一个小小脚本……所以我没用过。如果有人感兴趣的话可以试试。 改变输出格式以便与其他软件协作hyperfine 的命令行界面很好看，有进度条还有颜色。在除命令行之外的地方，她也做得很好。比如，hyperfine 可以直接用 --export-markdown 参数生成 markdown 表格，接着你就可以直接把结果插进 README 里面。她还可以导出 json 格式的测试结果，方便之后再用脚本处理，做些可视化什么的（hyperfine 的仓库就附带了许多可视化脚本，很好玩）。 总结测量程序性能的方式有很多。相比那些在函数调用上插桩（gprof）或读 PMC 寄存器（perf）的东西来说，单纯的计时也许太简陋了一些。但是第一次参观 profiler，却并不觉得震撼。因为我早已遇见，独属于我的 benchmarking tool。初遇你的那天起，齿轮便开始转动，却无法阻止丧失的预感。尽管已经拥有了很多，但让我们再多加一个吧。可以给我最后一个加速比吗？我不愿遗忘","link":"/2023/10/01/tutorial/hyperfine/main/"},{"title":"一些能够节省按键次数的 bash 配置","text":"一些能够节省按键次数的 bash 配置众所周知，敲击键盘的同时，人的手指会经历一系列的磨损。长此以往，手指就会变短。为了保护手指，使用下面的 bash 配置，成为和我一样能少按键盘就少按键盘的人吧！ 给命令起单个字符的别名对于一些常用的命令，如果没有重复命令，可以给他们起单个字符的别名。 123456789alias a='ls -A'alias g='grep'alias j='jobs -l'alias l='ls'alias o='xdg-open'alias r='rm'alias t='task' # taskwarrior: 一个 todo-list 小软件alias v='vi'alias -- -='cd -' # 这里的意思是将 - 作为 cd - 的别名 但是这些写法在 xargs 这里出了点小问题： 12345% 17:51:28 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 alias x='xargs'% 17:51:32 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 l|x g helloxargs: g: No such file or directory 我们的本意是想让它运行 1ls | xargs grep hello 但由于 g 并不是命令，xargs 报了错。要是我们想让 x 被展开为 xargs 后，其后的 g 继续被展开，我们可以这样写： 1alias x='xargs ' # 注意，xargs 与第二个单引号之间有一个空格 之后再运行 123456% 17:58:29 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr1 la.md% 17:58:30 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr1 l|x g '`xargs`'由于 `g` 并不是命令，xargs 报了错。要是我们想让 `x` 被展开为 `xargs` 后，其后的 `g` 继续被展开，我们可以这样写： 就好了。这是 bash 的小特性，结尾的空格可以让下一个标识符展开（如果是别名的话）。同理，我们对 sudo 也做类似的事情： 1alias s='sudo ' 太方便辣！ 此外，单个 % 的作用和 fg 相同，都是让后台进程回到前台。 给有歧义的命令们起一样的名字我日常使用 find 和 file 比较频繁，正常人在缩写他们时，都会想到用 f 来作为它们的别名。而如果一个用 f 作了别名，另一个就只能用其他奇奇怪怪的缩写。有没有办法让它们共用一个名字呢？ 由于脑机接口尚未开发完成，shell 无法通过魔法装置读取我们的思想，知道我们在运行 f 时究竟是想运行 find，还是 file，我们只能手动实现一个 shell 函数，根据上下文猜测输入时究竟想要什么。 （怎么有种 Perl 猜代码块和匿名哈希的感觉） 这是一个简单的示例，可以根据实际使用情况另作调整。 1234567891011121314151617181920212223242526272829303132333435# find, filef(){ local i local expect_find= # 如果发现身处管道之中，stdin 里不是终端，有输入，则猜测想要 # 确定 stdin 中文件的类型 if ! [ -t 0 ]; then file - # 如果 stdin 是终端，但是没有参数，猜测是想要递归列出当前目录 # 下的文件，调用 find elif [ -z &quot;$1&quot; ]; then find else # 如果有参数以连字符（-）打头，则猜测是 find 的参数， # 比如 -name -type 之类的。 # 如果参数没有以连字符打头的，则猜测是 file 的参数，参数 # 都是文件名 for i in &quot;$@&quot;; do if [ &quot;${i:0:1}&quot; = '-' ]; then expect_find=y break fi done if [ -n &quot;$expect_find&quot; ]; then find &quot;$@&quot; else file &quot;$@&quot; fi fi} 实际使用看起来还不错。 12345678910111213% 18:56:38 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 f../a.md% 18:56:40 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 f &lt; a.md/dev/stdin: UTF-8 Unicode text% 18:56:42 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 f -type f./a.md% 18:56:45 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 f a.mda.md: UTF-8 Unicode text 这样基本符合日常使用，无法处理的边边角角的情况打全名也不是不能接受啦。 还有一些类似的函数： 12345678910111213141516171819c(){ # 复制？还是复制到剪贴板？ if [ -t 0 ] &amp;&amp; [ &quot;$#&quot; -ge 2 ]; then cp &quot;$@&quot; else clip &quot;$@&quot; fi}p(){ # 调用分页器（pager）？还是打印当前目录？ if [ -z &quot;$1&quot; ] &amp;&amp; [ -t 0 ]; then pwd else less -F &quot;$@&quot; fi} 给小工具更多的默认行为有时一些操作总是连在一起的，比如新建文件夹然后切换进去，我们可以用这样的神奇函数： 123456789md(){ if [ -z &quot;$2&quot; ]; then mkdir &quot;$1&quot; || return cd &quot;$1&quot; else mkdir &quot;$@&quot; fi} 或者我们经常将别处的文件移到当前文件夹，使用这个函数，这样我们可以省略最后那个 . 参数。因为奇怪的原因，只有在有且仅有一个参数时才会有这个功能。有多个参数时总会有无法解决的歧义问题。（不过这样已经足够好了） 12345678910m(){ if [ -z &quot;$1&quot; ]; then echo too few arguments elif [ -z &quot;$2&quot; ]; then mv &quot;$1&quot; . else mv &quot;$@&quot; fi} 当然，执行 cd 再执行 ls 应该是某种常规的操作，每年因为这项操作没有优化，无数根手指被磨短。当然可以把 cd 变成 cd &amp;&amp; ls，但是我们想到了一种更加酷炫的方法来解决这个问题，放在另一个部分说。 开启大量 shell 内置特性bash 内置了大量方便的扩展特性，这些特性可以使用 shopt -s &lt;特性名称&gt; 打开。比如：shopt -s autocd。 autocd自动切换目录……意思是假设当前目录下有一个名为 my-doc 的子目录，可以用 my-doc 取代 cd my-doc。这有一个小问题，由于补全时 bash 并不知道想输入的是目录还是指令，指令会和目录一起进入补全列表，又慢又难选。使用 ./my-doc 会好很多。 checkwinsize在终端窗口变化时重新设置 $LINES 和 $COLUMNS dotglob匹配隐藏文件，这个按个人需求而定？我是觉得这个选项很酷所以打开了。 extglob扩展的匹配，完全没用！真的好难用，试图给通配符加上一些正则表达式的扩展，还没有 find sed grep xargs 香。 failglob没有匹配时报错而不是将模式作为参数传递给程序。非常有用，能避免一堆奇奇怪怪问题。比如： 开启前： 12345% 19:21:49 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 touch *.c # 我要摸摸所有 c 文件% 19:21:49 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 ls a.md '*.c' # 啊不好了，他给我新建了一个 ./*.c 开启后： 123456% 19:23:23 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 touch *.c-bash: no match: *.c # 没有找到！% [1] 19:23:28 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 lsa.md globstar让 ** 通配符支持递归进子文件夹的匹配，比如 my/**/file 可以匹配 my/magic/powerful/fancy/file ，可以用来部分代替 find。 全自动的 ls有时我们希望当前目录下文件发生改变，或工作目录发生改变时，自动 ls 一下展示目录现状。 我们很容易写出这样的函数： 123456789101112131415# 第一次运行，保存工作目录和当前目录内容（的哈希值）LAST_LS=$(command ls | sum)LAST_PWD=&quot;$PWD&quot;_prompt_smart_ls(){ local this_ls this_ls=$(command ls | sum) if [ &quot;$LAST_LS&quot; != &quot;$this_ls&quot; ] || [ &quot;$LAST_PWD&quot; != &quot;$PWD&quot; ]; then LAST_LS=&quot;$this_ls&quot; LAST_PWD=&quot;$PWD&quot; ls return fi} 之后，每调用一次 _prompt_smart_ls，它都会检查工作目录和当前目录内容，如果发现有不一样的地方，就 ls 一次。我们只要想办法每执行一次指令，就调用一次这个函数就行了。 （当然也可以用其他的检查方式，比如使用神奇的守护进程监视文件系统变化，再和 shell 通信，但是其他方法好像都没有每执行完一次指令就检查一次简单有效） 怎么做到每执行一次命令，就调用一次函数呢？ 1PROMPT_COMMAND='_prompt_smart_ls' 使用 bash 魔法变量，bash 会在执行每条命令后自动执行 PROMPT_COMMAND 这个变量里所存的命令。 最后效果： 12345678910% 20:17:09 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 touch testa.md test% 20:17:12 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 rm testa.md% 20:17:13 jyi@Syameimaru-Aya ~/s/m/b/n/shell-abbr0 cd /bin/ dev/ home/ lib/ lost+found/ mnt/ proc/ run/ srv/ tmp/ var/boot/ etc/ init* lib64/ media/ opt/ root/ sbin/ sys/ usr/ 太炫酷了！ 更多的 cd我们知道设置了 autocd 之后，输入 .. 会自动切换到上级目录……我们可以做得更多！ 12alias ...='cd ../..'alias ....='cd ../../../' 使用外部工具！仔细想了想，发现平时使用 z.sh 按访问频率自动跳转时，有时会跳转到自己不希望的位置，如果能够选择跳转到哪里就好了。 我们还需要可见的界面！这个想法是从 zsh 的补全里偷来的，感觉可以上下左右选择非常厉害。 所以使用 fzf 配合 z.sh，做出非常友好的跳转方式： 123456fz(){ local dir dir=&quot;$(z | sed 's/^[0-9. \\t]*//' |fzf -1 -0 --no-sort --tac +m)&quot; &amp;&amp; \\ cd &quot;$dir&quot; || return 1} 正确的重新加载配置的方法修改了 .bashrc 文件，想要试用一番！怎么加载配置文件呢？ source ~/.bashrc：不好，前任配置文件中残留的 alias 尸体、环境变量可能会影响使用，尤其是写错了的情况下…… bash：不好，退出的时候也要连按许多 exit 或者 Ctrl-D bash; exit：比上一个好，但是会影响 $SHLVL 变量，可能会对一些奇特脚本（比如 debian 11 下的 ~/.bash_logout）造成影响。 exec bash：非常好！用了 exec bash，亩产一千八！ 所以这是重新加载配置文件的缩写（reload）： 1alias rl='exec bash' 总结 打键盘是不错，但是也别敲过了头。打键盘打得太多，手指可就被磨短了。","link":"/2023/10/01/tutorial/shell-abbr/main/"},{"title":"博客园上可用的 markdown 目录生成器","text":"为 markdown 写的文章生成目录，使其在博客园上可用。 完整代码123456789101112131415161718192021222324252627use v5.12;use utf8;use open ':utf8';use open ':std', ':utf8';my @subtitle_number;say &quot;# 目录&quot;;while (&lt;&gt;) { next if /^```/ ... /^```/; if (/^(#+)\\s*(.*?)\\s*$/) { my ($level, $title) = (length($1), $2); my $indent = &quot; &quot; x $level; my $id = $title; $id =~ s/[^_[:^punct:]]//g; $id =~ s/[[:space:]]/-/g; $id = lc $id; @subtitle_number = splice @subtitle_number, 0, $level; $subtitle_number[$level - 1] += 1; my $subtitle_number = join &quot;.&quot;, @subtitle_number; say &quot;$indent+ $subtitle_number [$title](#$id)&quot;; }}say &quot;&quot;; 这是一个 Perl 脚本，从 stdin 或者参数中读取文章，输出一份 markdown 代码，是文章的目录。可以直接复制粘贴使用，也可以和其他工具集成使用。 使用示例使用这样的命令： 1$ perl toc.pl main.md 可以得到这样的结果： 12345678910111213141516# 目录 + 1 [完整代码](#完整代码) + 2 [使用示例](#使用示例) + 3 [原理](#原理) + 3.1 [HTML 的链接语法](#html-的链接语法) + 3.2 [markdown 列表缩进](#markdown-列表缩进) + 4 [代码详解](#代码详解) + 4.1 [使用「现代」Perl](#使用现代perl) + 4.2 [支持 utf8 编码](#支持-utf8-编码) + 4.3 [主循环](#主循环) + 4.3.1 [跳过 markdown 的代码片段](#跳过-markdown-的代码片段) + 4.3.2 [匹配标题](#匹配标题) + 4.3.3 [设置缩进](#设置缩进) + 4.3.4 [从标题名字中获得其 id](#从标题名字中获得其-id) + 4.3.5 [获取标题的编号](#获取标题的编号) 原理HTML 的链接语法在大多数网页上，markdown 的链接语法会被编译成 HTML 的 &lt;a&gt; 标签。通常 &lt;a&gt; 标签会有 href 属性，内容是点击标签时跳转的目的地址。 有些页内元素带有 id 属性，比如这个例子： 1&lt;h3 id=&quot;interactive-shell&quot;&gt;interactive shell&lt;/h3&gt; 在这个例子里 &lt;h3&gt; 标签有 id 属性，值是 interactive-shell。这个值同样可以用作 &lt;a&gt; 标签的目的地址。 当目的地址是页内元素的 id 时，点击 &lt;a&gt; 标签时便会跳转到该元素的位置。博客园给每个标题都自动分配了一个 id，利用这几点，就可以实现「点击目录项目跳转到对应章节」的功能。 markdown 列表缩进在 markdown 中，列表以 + - 和 * 开头。如果这些符号前面有空白字符，那么这些空白字符会被当成缩进，最终会体现在列表展示结果上，缩进越多的列表项目展示时会越靠右，缩进相同的列表项目会左对齐。利用这一点，可以实现目录的层次结构。 代码详解使用「现代」Perl1use v5.12; Perl 是个老古董语言，为了保持兼容性，有许多好玩/有用的特性默认没有打开。不过我们可以使用 use vX.YY 的 pragma 来指定自己想使用的 Perl 的版本号，从而开启这些好玩的特性。 支持 utf8 编码123use utf8;use open ':utf8';use open ':std', ':utf8'; 同上，因为 Perl 是个老古董语言，所以默认全世界都用 ASCII 编码。我们要开启它对 utf8 的支持。 这里第一行是让 Perl 用 utf8 的方式来解释这份源代码（有点像 python2 里面的 # -*- coding: utf-8 -*- 的 pragma）。 第二行是让 Perl 读所有文件时，读后解码 utf8；写所有文件时，写前编码 utf8。Perl 中为了方便数据处理，存在 IO Layer 的概念。layer 可以看做数据的转换器，数据在进行输入/输出时，会经过这些 layer 逐层处理。常用的 layer 有 :crlf（读时将 CR-LF 序列转换成 CR，写时反过来，用来对付 Windows 系统）和 :encoding（用来编解码文件）。还有些邪恶的 layer 可以实现自动压缩解压、base16 编码等功能。所以有时遇到输出到 stdout 和输出到文件中，内容不一致的情况，可以检查一下是不是用的 layer 不同造成的。 第三行是在设置 stdio 的 layer。因为 stdio 在 Perl 程序运行前就已经打开了，所以需要单独设置一下。 主循环就是那个巨大的 while 循环。它每次会从输入中读取一行数据并放到 $_ 里面，直到读到文件结束。 1while (&lt;&gt;) { 可以发现我们并没有处理命令行参数，这是因为 &lt;&gt; 这个操作符会替我们完成这项工作。&lt;&gt; 操作符的意思是，如果有命令行参数，那么就把命令行参数当做文件名打开文件，并且将文件内容作为输入；否则就把 stdin 作为输入。每调用一次 &lt;&gt; 操作符会读取一行，返回这一行的内容。如果没有变量来接收 &lt;&gt; 操作符的返回值，那么 &lt;&gt; 操作符会把返回值存在特殊变量 $_ 中。 跳过 markdown 的代码片段1next if /^```/ ... /^```/; 这一行用来跳过 markdown 的代码片断。是一种被称为 flip-flop 的语法。上面代码的意思是，「如果在两个代码标记之间，那么执行 next 语句」。大概和下面的东西等价： 123456789101112131415# 这句在循环外头my $in_codeblock = 0;# 这下面的在循环里头if ($in_codeblock) { next;}if (/^```/ &amp;&amp; $in_codeblock == 0) { $in_codeblock = 1;}if (/^```/ &amp;&amp; $in_codeblock == 1) { $in_codeblock = 0;} flip-flop 是一种很方便的语法，可以让人少写很多代码。最重要的是不需要对那一堆烦人的标志变量命名了。 匹配标题用一个正则表达式来匹配标题并且获得需要的信息： 12if (/^(#+)\\s*(.*?)\\s*$/) { my ($level, $title) = (length($1), $2); 这个意思是，如果遇到「开头是若干个 #，中间有一堆字符」这种模式，就认为匹配到标题了。$level 和 $title 分别是标题的层级和名称。因为正则表达式在 Perl 中用的特别多，所以直接做进语言里面去了，可以随手写，不需要另外调库。 设置缩进1my $indent = &quot; &quot; x $level; $level 总是个整数。这里用字符串重复操作符 x，来获得与 $level 成正比的缩进长度。 从标题名字中获得其 id1234my $id = $title;$id =~ s/[^_[:^punct:]]//g;$id =~ s/[[:space:]]/-/g;$id = lc $id; 博客园会根据标题名称来设置其 HTML 标签的 id。有人托梦告诉我说，id 就是标题去掉所有标点符号但是保留下划线 _，把空白字符换成连字符 -，并且把所有字母变为小写之后的结果。所以用正则表达式写了一个。 获取标题的编号123@subtitle_number = splice @subtitle_number, 0, $level;$subtitle_number[$level - 1] += 1;my $subtitle_number = join &quot;.&quot;, @subtitle_number; 生成的目录里面会有类似 X.Y.Z.W 这样的标题编号。这一部分代码就用来处理标题编号的生成问题。懒得写了……","link":"/2023/10/01/tutorial/toc-for-cnblogs/main/"},{"title":"Bottles 安装","text":"Bottles 安装好名字！Bottles 是类似 winetricks 的小软件，用于自动配置 wine、自动安装并配置软件。至于为什么有了 winetricks 还需要新的小软件，bottles 在他们官网上给出了解释：bottles 希望提供中心化的依赖处理系统，并且希望拥有比 winetricks 更强的扩展性。总之不是重复造轮子就对了。 之前试着用 winetricks 一键安装 qq，结果有一个托管在 ftp.hp.org 上的文件一直下载不下来。接着我就把 winetricks 扬了。 Wine bottles，酒瓶子。:D 安装和安装过程的问题修复参考官方的安装指南 直接使用包管理器安装官方的安装指南里面说，bottles 在多个发行版的源里有包。比如 fedora，就可以使用 sudo dnf install bottles 来安装。其他支持的发行版可以去安装指南里头看看。 但是 debian 源竟然没有包，神奇……明明代码目录里有个 debian/，这不指明了是要人打包吗？ 编译 deb 包，再使用包管理器安装编译 deb 包因为 debian 源里面没有 bottles 的包，所以我们需要编译代码。同时为了维护依赖，便于删除，我们利用代码目录里面 debian/ 下的东西把它打成 deb 包，再使用 apt 命令安装。 bottles 使用 meson 和 ninja 作为构建系统。听说这两个东西很先进，打算改天去学一下。从 devgenius.io 上现学了怎么使用 meson/ninja 打 deb 包： 首先安装 debhelper build-essentials 和 dh-make。其中 debhelper 和 dh-make 是 debian 的软件包构建相关工具。build-essentials 则是软件开发的基础工具，包含 make 等小工具。 1sudo apt install debhelper build-essentials dh-make 接着下载代码并且进入环境： 12git clone https://github.com/bottlesdevs/Bottlescd Bottles 然后运行 debian 包的自动配置脚本，指定构建系统为 meson： 1dh_auto_configure --buildsystem=meson 最后运行构建软件包的命令。参数的 -b 是指仅构建二进制的 deb 包。因为是命令是偷来的所以也不是很清楚参数有什么用…… 1dpkg-buildpackage -rfakeroot -us -uc -b 回到上级目录，发现 deb 包出现了！ 1cd ../ &amp;&amp; ls -l 输出： 12345total 284drwxrwxr-x 1 root root 672 Mar 5 20:02 Bottles-2022.2.28-trento-2/-rw-r--r-- 1 root root 6872 Mar 5 20:02 com.usebottles.bottles_2022.2.28-trento-2_amd64.buildinfo-rw-r--r-- 1 root root 5004 Mar 5 20:02 com.usebottles.bottles_2022.2.28-trento-2_amd64.changes-rw-r--r-- 1 root root 269408 Mar 5 20:02 com.usebottles.bottles_2022.2.28-trento-2_amd64.deb 安装 1sudo apt -y install ./com.usebottles.bottles.*.deb 检查有没有 bottles 命令 1type bottles 如果出现 1bottles is /usr/bin/bottles 说明安装成功！ 启动和启动过程的问题修复在我这儿 bottles 安装好后运行命令并不能直接启动，会报错： 123456789101112131415161718% [1] 20:43:10 jyi@Syameimaru-Aya ~0 bottlesTraceback (most recent call last): File &quot;/usr/bin/bottles&quot;, line 56, in &lt;module&gt; from bottles import main File &quot;/usr/share/bottles/bottles/main.py&quot;, line 32, in &lt;module&gt; from bottles.window import MainWindow File &quot;/usr/share/bottles/bottles/window.py&quot;, line 35, in &lt;module&gt; from bottles.views.details import DetailsView File &quot;/usr/share/bottles/bottles/views/details.py&quot;, line 25, in &lt;module&gt; from bottles.views.bottle_details import BottleView File &quot;/usr/share/bottles/bottles/views/bottle_details.py&quot;, line 36, in &lt;module&gt; from bottles.dialogs.generic import MessageDialog File &quot;/usr/share/bottles/bottles/dialogs/generic.py&quot;, line 20, in &lt;module&gt; gi.require_version('GtkSource', '4') File &quot;/usr/lib/python3/dist-packages/gi/__init__.py&quot;, line 129, in require_version raise ValueError('Namespace %s not available for version %s' %ValueError: Namespace GtkSource not available for version 4 经过搜索发现这里是缺少了 gir1.2-gtksource-4 的库。估计是写依赖时写漏了。使用 sudo apt install gir1.2-gtksource-4 安装上就可以正常运行了。 简易使用安装运行之后会出现欢迎界面，点几下 “下一步” 之后 bottles 会下载相关组件。这个很慢，可能是因为服务器在国外。多等一会儿就好了。等的时候可以写写博客之类的…… 之后使用方式非常显然，所以就不写了（咕了）。","link":"/2023/10/01/tutorial/wine-bottles/main/"},{"title":"CSAPP Data Lab 做题记录（上）","text":"CSAPP Data Lab 做题记录（上）准备工作访问 http://csapp.cs.cmu.edu/3e/labs.html 试图下载网页上醒目的 datalab.tar，发现需要身份验证。后来发现点后面的小东西可以直接下载。读了 readme 之后知道 datalab.tar 好像是教师用的，用来生成学生的包（datalab-handout），datalab-handout 才是学生用的。 读文档，知道实验是要用位运算来模拟各种整数运算，还要用整数运算模拟浮点运算。好像评测还实现了一个小工具来查是否用到了违规的操作符。 看文档上说需要安装 bison 和 flex，以为检查违规小工具也需要编译，正打算看一下代码发现包里直接发了个二进制文件下来…… 发现评测程序是用 Perl 写的，古老。 Driverlab.pm 里好像手写了一个 http 客户端？看起来是搞那个 Beat the Prof 比赛的，应该不用管它。 依照手册指示，要先 make 一下把 btest 给编译好。结果遇到神奇问题： 12345678910111213141516171819202122% 09:19:42 jyi@Syameimaru-Aya ~/s/c/d/c/d/datalab-handout0 makegcc -O -Wall -m32 -lm -o btest bits.c btest.c decl.c tests.cIn file included from btest.c:16:/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: No such file or directory 27 | #include &lt;bits/libc-header-start.h&gt; | ^~~~~~~~~~~~~~~~~~~~~~~~~~compilation terminated.In file included from decl.c:1:/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: No such file or directory 27 | #include &lt;bits/libc-header-start.h&gt; | ^~~~~~~~~~~~~~~~~~~~~~~~~~compilation terminated.In file included from /usr/lib/gcc/x86_64-linux-gnu/10/include/limits.h:195, from /usr/lib/gcc/x86_64-linux-gnu/10/include/syslimits.h:7, from /usr/lib/gcc/x86_64-linux-gnu/10/include/limits.h:34, from tests.c:3:/usr/include/limits.h:26:10: fatal error: bits/libc-header-start.h: No such file or directory 26 | #include &lt;bits/libc-header-start.h&gt; | ^~~~~~~~~~~~~~~~~~~~~~~~~~compilation terminated.make: *** [Makefile:11: btest] Error 1 检查了一发发现是 makefile 里指定了 -m32 但是我没有 32 位的库，装了个 gcc-multilib。至于为啥不用 -m64 编译……因为那里面说什么 “not 64-bit safe”，没太懂。 题目列表bitXor给定两个数，返回他们的异或。 首先由真值表写出把异或运算写成最小项之和的形式，就是 $X \\oplus Y = X\\bar{Y} + \\bar{X}Y$。然后跑跑发现零分，是因为我们没有 | 可以用……用德摩根定律画画柿子得到 $\\bar{\\bar{X\\bar{Y}}\\bar{\\bar{X}Y}}$，避开 |，就能过了。 123int bitXor(int x, int y) { return ~(~(~x &amp; y) &amp; ~(x &amp; ~y));} tmin返回最小的有符号整数。 题目假设机器使用补码表示法，我们知道这个数的位模式应该长得比较像 1000…000。题目又假设了我们机器上的整数都是 32 位的，所以我们把 1 左移 31 位返回就行了。 123int tmin(void) { return 1 &lt;&lt; 31;} isTmax判断给定的 x 是不是最大的有符号整数。 考虑到题目假定机器采用补码表示法，最大的有符号整数 tmax 的位模式应该是 01111…111。好像把 tmin 的结果取反就是了，但是他没给 &lt;&lt; 操作符，题目又禁止使用超过 255 的整数，所以 tmax 应该搞不出来。 倒是有一个检查加一向上溢出（假设溢出的行为和无符号整数差不多）取反后是不是和自己相等（~(x + 1) == x）的想法，但是有符号数溢出好像是 ub 啊。题目也没有规定溢出会采用什么方式。 先这么做好了……-1 要特判一下因为 -1 取反加一后马上就溢出了。 123int isTmax(int x) { return (!((~(x + 1)) ^ x)) &amp; (!!(x + 1));} allOddBits判断给定 x 的奇数二进制位上是否全为 1。 ……这样吗？ 123456int allOddBits(int x) { return (x &gt;&gt; 1) &amp; (x &gt;&gt; 3) &amp; (x &gt;&gt; 5) &amp; (x &gt;&gt; 7) &amp; (x &gt;&gt; 9) &amp; (x &gt;&gt; 11) &amp; (x &gt;&gt; 13) &amp; (x &gt;&gt; 15) &amp; (x &gt;&gt; 17) &amp; (x &gt;&gt; 19) &amp; (x &gt;&gt; 21) &amp; (x &gt;&gt; 23) &amp; (x &gt;&gt; 25) &amp; (x &gt;&gt; 27) &amp; (x &gt;&gt; 29) &amp; (x &gt;&gt; 31) &amp; 1;} 测了一下发现性能分数没有拿到，最多只能使用 12 个操作符，而这里用了 33 个。考虑进行优化。因为我们可以直接使用 8 位整数，所以我们可以考虑将输入的东西每 8 位与一下，再用一个掩码检查得到的东西奇数位上是否都为 1。这样就能减少计算了。 123int allOddBits(int x) { return !((x &amp; (x &gt;&gt; 8) &amp; (x &gt;&gt; 16) &amp; (x &gt;&gt; 24) &amp; 0xaa) ^ 0xaa);} 只用了 9 个操作符耶！ negate求给定数的相反数。 这个可以使用我们熟知的小结论，把 x 取反后再加一直接得到结果，非常简单。 123int negate(int x) { return (~x) + 1;} isAsciiDigit判断给定输入是不是 ASCII 编码中的数字。 我们已经有了比较两个数字是否相等的便利算法，只要打表检查是否等于每个可能的数字，将结果或起来就是最终答案。但是这样显然是拿不到性能分的嘛。 嗯……如果 x 的最高位为 1，那它是个负数，就不是 ASCII 的数字了。排除这种情况后，接下来就只要考虑正数比大小。 发现异或的结果的最高位是两个数字第一个不同之处，找出谁是 1 谁就更大。问题就变成了如何取一个数的最高位。并没有想到什么取一个数最高位的便利算法…… 考虑利用一下题目特性，ASCII 的 0 和 9 是 110000 和 111001，想到搞一个东西来检查 x 的前面 26 位是否全为 0，而且第 5、6 位为 1。接着再判断后四位是否符合第四位为 0，或者第 2、3 位为零…… 折腾一下得到这样的答案： 1234int isAsciiDigit(int x) { return (!((~0x3f) &amp; x)) &amp; (!((0x30 &amp; x) ^ 0x30)) &amp; (!(0x8 &amp; x) | (!(0x6 &amp; x)));} 轻松过关 conditional实现类似三目运算符的功能。 要实现 x ? y : z 的话，应该很容易想到 (!!x) * y + (!x) * z 这种的……但是我们没有乘号。可以想到使用与号替代一下，就是想办法弄一个掩码，当 x 为真时它是全 1，x 为假时它是全零这种的。感觉比较简单。 代码里为了节省符号把掩码弄成当 x 为真时是全 0，x 为假时是全 1。使用方法还是差不多的吧。 123456789int conditional(int x, int y, int z) { int mask = !x; mask = (mask &lt;&lt; 1) | mask; mask = (mask &lt;&lt; 2) | mask; mask = (mask &lt;&lt; 4) | mask; mask = (mask &lt;&lt; 8) | mask; mask = (mask &lt;&lt; 16) | mask; return ((~mask) &amp; y) | (mask &amp; z);} 写后面的 howManyBits 的时候获得了重大技术革新，现在有一种便利操作来生成掩码了！ 1234int conditional(int x, int y, int z) { int mask = (~(!x)) + 1; return ((~mask) &amp; y) | (mask &amp; z);} 如果 x 是 0，则 ~(!x) 位模式为 1111…1110，加 1 后刚好是全 1。 如果 x 是 1，则 ~(!x) 位模式为 1111…1111，加 1 向上溢出后刚好是全 0。 isLessOrEqual判断给定的两个数是否满足小于等于关系。 小于等于就是不大于嘛，接下来考虑判断两个数的大于关系。 这个好像在 isAsciiDigit 那个题里的踩过一次，所以接着思路往下想……如何取一个数的最高位。发现取最高位的话怎么写都会拿不完性能分。 突然想到好像两个数相减一下再判断结果是否为正数就行，原来刚刚想那么多是脑子打结了。 先判断两个数是否正好为一正一负，如果是的话可以直接给结果。否则相减判断结果正负，这时两个同号的数相减必不可能溢出。 1234int isLessOrEqual(int x, int y) { return (((x &gt;&gt; 31) &amp; 1) | (!(y &gt;&gt; 31))) &amp; ((((x &gt;&gt; 31) &amp; 1) &amp; (!(y &gt;&gt; 31))) | (!((y + (~x) + 1) &gt;&gt; 31)));} 拿下。 logicalNeg实现逻辑非，不能使用感叹号。 感觉和 allOddBits 很像！只不过那个是求奇数位上全为 1，这里是求存在某一位为 1。 用类似的方法实现一下就好啦。 12345678int logicalNeg(int x) { x = x | (x &gt;&gt; 16); x = x | (x &gt;&gt; 8); x = x | (x &gt;&gt; 4); x = x | (x &gt;&gt; 2); x = x | (x &gt;&gt; 1); return 1 ^ (x &amp; 1);} 最后 return 那个奇怪的表达式其实是 1 - x 拆过来的。发现直接写 2 + (~x) 会拿不到性能分，符号刚好多一个。 howManyBits求最少用多少个位可以表示出给定数字。 其实就是 $\\log_{2}$ 啦。 先假定 x 是负数，根据补码表示法我们需要能够表示 $[ x, -x - 1 ]$ 的所有数。全部当成无符号整数之后需要表示的范围是 $[0, ((x) &lt;&lt; 1) + 1]$，只要我们能够用一些位表示出最大的数，那么这些位一定可以表示出所有数。因此答案就是 $\\log_{2}(((x) &lt;&lt; 1) + 1)$（向上取整）。 同理，如果 x 是正数，则需要能够表示 $[ -x - 1, x ]$ 的所有数，答案是 $\\log_{2}((x &lt;&lt; 1) + 1)$。 至于如何取对数……猜测是要使用类似 logicalNeg 和 allOddBits 那样类似分治（？）的做法来完成，先考虑分成两半的情形：如果高 16 位不为零，可以给答案加上 16，接着再把高 16 位移动到低 16 位，按照类似的方式处理低 16 位；如果高 16 位为零，则直接处理低 16 位。依次类推直到处理完只剩一位的情况。 用力实现一下就好了。 12345678910111213141516171819202122232425262728293031int howManyBits(int x) { int ans = 0; int h16, h8, h4, h2, h1, h0; int sign = x &gt;&gt; 31; int range = (((x &amp; (~sign)) | ((~x) &amp; sign)) &lt;&lt; 1) + 1; h16 = (~(!!(range &gt;&gt; 16))) + 1; ans = ans + (h16 &amp; 16); range = range &gt;&gt; (h16 &amp; 16); h8 = (~(!!((range &gt;&gt; 8) &amp; 0xff))) + 1; ans = ans + (h8 &amp; 8); range = range &gt;&gt; (h8 &amp; 8); h4 = (~(!!((range &gt;&gt; 4) &amp; 0xf))) + 1; ans = ans + (h4 &amp; 4); range = range &gt;&gt; (h4 &amp; 4); h2 = (~(!!((range &gt;&gt; 2) &amp; 0x3))) + 1; ans = ans + (h2 &amp; 2); range = range &gt;&gt; (h2 &amp; 2); h1 = (~(!!((range &gt;&gt; 1) &amp; 0x1))) + 1; ans = ans + (h1 &amp; 1); range = range &gt;&gt; (h1 &amp; 1); h0 = (~(range &amp; 0x1)) + 1; ans = ans + (h0 &amp; 1); return ans;} 真不容易！","link":"/2023/10/01/note/csapp-lab/datalab/a/"},{"title":"CSAPP Data Lab 做题记录（下）","text":"CSAPP Data Lab 做题记录（下）摸了好几天，来做浮点部分…… 题目列表floatScale2传入一个无符号整数，把它当作单精度浮点数，乘二后输出。 很自然地想到提取出符号、阶码和尾数，接着根据是否为规格化的浮点数分情况处理，拼起来返回，比较简单。 12345678910111213141516171819202122unsigned floatScale2(unsigned uf) { int sign, expo, frac; int bias = 127; sign = (uf &gt;&gt; 31) &amp; ((1 &lt;&lt; 1) - 1); expo = (uf &gt;&gt; 23) &amp; ((1 &lt;&lt; 8) - 1); frac = uf &amp; ((1 &lt;&lt; 23) - 1); if (expo == 0xff) return uf; if (expo) { ++expo; if (expo == 0xff) frac = 0; } else { frac *= 2; if (frac &amp; (1 &lt;&lt; 23)) { expo = 1; frac &amp;= ~(1 &lt;&lt; 23); } } return (sign &lt;&lt; 31) | (expo &lt;&lt; 23) | frac;} floatFloat2Int传入一个无符号整数 uf，把它当作单精度浮点数，返回它截断后的整数部分。也就是 (int)uf。如果出现溢出，则返回 0x80000000u（书上说这是与 Intel 兼容的微处理器指定的 “整数不确定” 值）。 感觉也比较简单……弄出阶码、尾数之后，暴力移位就行了。 代码里最后根据 sign 决定返回 ans 还是 -ans，而没有考虑最终结果为 INT_MIN，导致计算 ans 时溢出的问题。是因为 32 位的 float 类型无法精确表示 32 位的 INT_MIN，所以这里不用考虑 int 正负表示区间不对称的问题。 12345678910111213141516171819202122232425int floatFloat2Int(unsigned uf) { int sign, expo; unsigned frac; int ans; int bias = 127; int error = 0x80000000u; sign = (uf &gt;&gt; 31) &amp; ((1 &lt;&lt; 1) - 1); expo = (uf &gt;&gt; 23) &amp; ((1 &lt;&lt; 8) - 1); frac = uf &amp; ((1 &lt;&lt; 23) - 1); if (expo == 0xff) return error; expo -= bias; if (expo &lt; 0) return 0; if (expo &gt; 31) return error; frac |= (1 &lt;&lt; 23); frac &lt;&lt;= 8; frac &gt;&gt;= (31 - expo); ans = frac; if (sign) ans = -ans; return ans;} floatPower2传入一个整数 $x$，返回单精度浮点数 $2^x$。如果结果太小则返回 0，太大则返回 +INF。 非常简单，只要改阶码部分，尾数部分保持全零即可。 12345678910111213unsigned floatPower2(int x) { int bias = 127; int sign = 0; int expo = x + bias; int frac = 0; if (expo &gt;= 0xff) expo = 0xff; if (expo &lt;= 0) expo = 0; return (sign &lt;&lt; 31) | (expo &lt;&lt; 23) | frac;} 总结总体来看浮点数部分比整数部分简单，没准是因为前面写整数时把各种运算练得比较熟了？ 做完了之后感觉自己对计算机中数字表示理解加深了甚至感觉可以全用位运算来实现各种操作符。 还有就是觉得整数的补码表示与 IEEE754 浮点数的一些性质特别神奇，怎么说不愧是广泛使用的标准。 调试时用了不少之前几乎没用过的联合体（union），应该说终于意识到这个东西怎么用了…… 测试结果","link":"/2023/10/01/note/csapp-lab/datalab/b/"}],"tags":[],"categories":[],"pages":[]}